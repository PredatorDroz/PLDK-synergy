{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Private Aggregation of Teacher Ensembles (PATE)\n",
    "\n",
    "\n",
    "\n",
    "![PATE chart](img/pate.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Subset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the [Data](http://pytorch.org/docs/stable/torchvision/datasets.html)\n",
    "\n",
    "Downloading may take a few moments, and you should see your progress as the data is loading. You may also choose to change the `batch_size` if you want to load more data at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 32\n",
    "\n",
    "CIFAR100_MEAN = (0.4914, 0.4822, 0.4465)\n",
    "CIFAR100_STD_DEV = (0.2023, 0.1994, 0.2010)\n",
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(CIFAR100_MEAN, CIFAR100_STD_DEV)])\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.CIFAR100(root='D:/research_2022/', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.CIFAR100(root='D:/research_2022/', train=False,\n",
    "                                  download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for returning dataloaders for a specified number of teachers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of teachers to essemble\n",
    "num_teachers = 100\n",
    "\n",
    "def get_data_loaders(train_data, num_teachers = 10):\n",
    "    teacher_loaders = []\n",
    "    data_size = len(train_data) // num_teachers\n",
    "\n",
    "    for i in range(num_teachers):\n",
    "        indices = list(range(i*data_size, (i+1) *data_size))\n",
    "        subset_data = Subset(train_data, indices)\n",
    "        loader = torch.utils.data.DataLoader(subset_data, batch_size=batch_size, num_workers=num_workers)\n",
    "        teacher_loaders.append(loader)\n",
    "\n",
    "    return teacher_loaders\n",
    "\n",
    "teacher_loaders = get_data_loaders(train_data, num_teachers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a train student set of 9000 examples and 1000 test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_train_data = Subset(test_data, list(range(9000)))\n",
    "student_test_data = Subset(test_data, list(range(9000, 10000)))\n",
    "\n",
    "student_train_loader = torch.utils.data.DataLoader(student_train_data, batch_size=batch_size, \n",
    "            num_workers=num_workers)\n",
    "student_test_loader = torch.utils.data.DataLoader(student_test_data, batch_size=batch_size, \n",
    "            num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining models\n",
    "\n",
    "I'm going to define a single model for all the teachers, the analysis does not depends on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(500, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, 500)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' ConvNet '''\n",
    "import torch.nn as nn\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, channel, num_classes, net_width, net_depth, net_act, net_norm, net_pooling, im_size = (32,32)):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.features, shape_feat = self._make_layers(channel, net_width, net_depth, net_norm, net_act, net_pooling, im_size)\n",
    "        num_feat = shape_feat[0]*shape_feat[1]*shape_feat[2]\n",
    "        self.classifier = nn.Linear(num_feat, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"MODEL DATA ON: \", x.get_device(), \"MODEL PARAMS ON: \", self.classifier.weight.data.get_device())\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return F.log_softmax(out)\n",
    "\n",
    "    def _get_activation(self, net_act):\n",
    "        if net_act == 'sigmoid':\n",
    "            return nn.Sigmoid()\n",
    "        elif net_act == 'relu':\n",
    "            return nn.ReLU(inplace=True)\n",
    "        elif net_act == 'leakyrelu':\n",
    "            return nn.LeakyReLU(negative_slope=0.01)\n",
    "        else:\n",
    "            exit('unknown activation function: %s'%net_act)\n",
    "\n",
    "    def _get_pooling(self, net_pooling):\n",
    "        if net_pooling == 'maxpooling':\n",
    "            return nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        elif net_pooling == 'avgpooling':\n",
    "            return nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        elif net_pooling == 'none':\n",
    "            return None\n",
    "        else:\n",
    "            exit('unknown net_pooling: %s'%net_pooling)\n",
    "\n",
    "    def _get_normlayer(self, net_norm, shape_feat):\n",
    "        # shape_feat = (c*h*w)\n",
    "        if net_norm == 'batchnorm':\n",
    "            return nn.BatchNorm2d(shape_feat[0], affine=True)\n",
    "        elif net_norm == 'layernorm':\n",
    "            return nn.LayerNorm(shape_feat, elementwise_affine=True)\n",
    "        elif net_norm == 'instancenorm':\n",
    "            return nn.GroupNorm(shape_feat[0], shape_feat[0], affine=True)\n",
    "        elif net_norm == 'groupnorm':\n",
    "            return nn.GroupNorm(4, shape_feat[0], affine=True)\n",
    "        elif net_norm == 'none':\n",
    "            return None\n",
    "        else:\n",
    "            exit('unknown net_norm: %s'%net_norm)\n",
    "\n",
    "    def _make_layers(self, channel, net_width, net_depth, net_norm, net_act, net_pooling, im_size):\n",
    "        layers = []\n",
    "        in_channels = channel\n",
    "        if im_size[0] == 28:\n",
    "            im_size = (32, 32)\n",
    "        shape_feat = [in_channels, im_size[0], im_size[1]]\n",
    "        for d in range(net_depth):\n",
    "            layers += [nn.Conv2d(in_channels, net_width, kernel_size=3, padding=3 if channel == 1 and d == 0 else 1)]\n",
    "            shape_feat[0] = net_width\n",
    "            if net_norm != 'none':\n",
    "                layers += [self._get_normlayer(net_norm, shape_feat)]\n",
    "            layers += [self._get_activation(net_act)]\n",
    "            in_channels = net_width\n",
    "            if net_pooling != 'none':\n",
    "                layers += [self._get_pooling(net_pooling)]\n",
    "                shape_feat[1] //= 2\n",
    "                shape_feat[2] //= 2\n",
    "\n",
    "\n",
    "        return nn.Sequential(*layers), shape_feat \n",
    "    \n",
    "    \n",
    "\n",
    "def get_default_convnet_setting():\n",
    "    net_width, net_depth, net_act, net_norm, net_pooling = 128, 3, 'relu', 'instancenorm', 'avgpooling'\n",
    "    return net_width, net_depth, net_act, net_norm, net_pooling\n",
    "\n",
    "net_width, net_depth, net_act, net_norm, net_pooling = get_default_convnet_setting()\n",
    "nets= ConvNet(channel=3, num_classes= 10,net_width=net_width, net_depth=net_depth, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling,im_size=(32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train(model, trainloader, criterion, optimizer, epochs=10, print_every=120):\n",
    "    model.to(device)\n",
    "    steps = 0\n",
    "    running_loss = 0\n",
    "    for e in range(epochs):\n",
    "        # Model in training mode, dropout is on\n",
    "        model.train()\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            steps += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model.forward(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader):\n",
    "    outputs = torch.zeros(0, dtype=torch.long).to(device)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        output = model.forward(images)\n",
    "        ps = torch.argmax(torch.exp(output), dim=1)\n",
    "        outputs = torch.cat((outputs, ps))\n",
    "    \n",
    "    return outputs    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training all the teacher models\n",
    "\n",
    "Here we define and train the teachers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and train the models for each teacher\n",
    "def train_models(num_teachers):\n",
    "    models = []\n",
    "    for t in range(num_teachers):\n",
    "        print(\"Training teacher {}\".format(t+1))\n",
    "        model = ConvNet(channel=3, num_classes= 100,net_width=net_width, net_depth=net_depth, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling,im_size=(32,32))\n",
    "        criterion = nn.NLLLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "        train(model, teacher_loaders[t], criterion, optimizer)\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "models = train_models(num_teachers) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregated teacher\n",
    "\n",
    "This function predict the labels from all the dataset in each of the teachers, then return all the predictions and the maximum votation after adding laplacian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define epsilon\n",
    "epsilon = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregated teacher\n",
    "\n",
    "This function makes the predictions in all the teachers, count the votes and add noise, then returns the votation and the argmax results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregated_teacher(models, data_loader, epsilon):\n",
    "    preds = torch.torch.zeros((len(models), 9000), dtype=torch.long)\n",
    "    for i, model in enumerate(models):\n",
    "        results = predict(model, data_loader)\n",
    "        preds[i] = results\n",
    "        \n",
    "    labels = np.array([]).astype(int)\n",
    "    for image_preds in np.transpose(preds):\n",
    "        label_counts = np.bincount(image_preds, minlength=10)\n",
    "        beta = 1 / epsilon\n",
    "\n",
    "        for i in range(len(label_counts)):\n",
    "            label_counts[i] += np.random.laplace(0, beta, 1)\n",
    "\n",
    "        new_label = np.argmax(label_counts)\n",
    "        labels = np.append(labels, new_label)\n",
    "    \n",
    "    return preds.numpy(), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "teacher_models = models\n",
    "preds, student_labels = aggregated_teacher(teacher_models, student_train_loader, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"\n",
    "This script computes bounds on the privacy cost of training the\n",
    "student model from noisy aggregation of labels predicted by teachers.\n",
    "It should be used only after training the student (and therefore the\n",
    "teachers as well). We however include the label files required to\n",
    "reproduce key results from our paper (https://arxiv.org/abs/1610.05755):\n",
    "the epsilon bounds for MNIST and SVHN students.\n",
    "\"\"\"\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# import tensorflow as tf\n",
    "#\n",
    "#\n",
    "# # These parameters can be changed to compute bounds for different failure rates\n",
    "# # or different model predictions.\n",
    "#\n",
    "# tf.flags.DEFINE_integer(\"moments\",8, \"Number of moments\")\n",
    "# tf.flags.DEFINE_float(\"noise_eps\", 0.1, \"Eps value for each call to noisymax.\")\n",
    "# tf.flags.DEFINE_float(\"delta\", 1e-5, \"Target value of delta.\")\n",
    "# tf.flags.DEFINE_float(\"beta\", 0.09, \"Value of beta for smooth sensitivity\")\n",
    "# tf.flags.DEFINE_string(\"counts_file\",\"\",\"Numpy matrix with raw counts\")\n",
    "# tf.flags.DEFINE_string(\"indices_file\",\"\",\n",
    "#     \"File containting a numpy matrix with indices used.\"\n",
    "#     \"Optional. Use the first max_examples indices if this is not provided.\")\n",
    "# tf.flags.DEFINE_integer(\"max_examples\",1000,\n",
    "#     \"Number of examples to use. We will use the first\"\n",
    "#     \" max_examples many examples from the counts_file\"\n",
    "#     \" or indices_file to do the privacy cost estimate\")\n",
    "# tf.flags.DEFINE_float(\"too_small\", 1e-10, \"Small threshold to avoid log of 0\")\n",
    "# tf.flags.DEFINE_bool(\"input_is_counts\", False, \"False if labels, True if counts\")\n",
    "#\n",
    "# FLAGS = tf.flags.FLAGS\n",
    "\n",
    "\n",
    "def compute_q_noisy_max(counts, noise_eps):\n",
    "    \"\"\"Returns ~ Pr[outcome != winner].\n",
    "\n",
    "  Args:\n",
    "    counts: a list of scores\n",
    "    noise_eps: privacy parameter for noisy_max\n",
    "  Returns:\n",
    "    q: the probability that outcome is different from true winner.\n",
    "  \"\"\"\n",
    "    # For noisy max, we only get an upper bound.\n",
    "    # Pr[ j beats i*] \\leq (2+gap(j,i*))/ 4 exp(gap(j,i*)\n",
    "    # proof at http://mathoverflow.net/questions/66763/\n",
    "    # tight-bounds-on-probability-of-sum-of-laplace-random-variables\n",
    "\n",
    "    winner = np.argmax(counts)\n",
    "    counts_normalized = noise_eps * (counts - counts[winner])\n",
    "\n",
    "    counts_rest = np.array([counts_normalized[i] for i in range(len(counts)) if i != winner])\n",
    "    q = 0.0\n",
    "    for c in counts_rest:\n",
    "        gap = -c\n",
    "\n",
    "        q += (gap + 2.0) / (4.0 * math.exp(gap))\n",
    "\n",
    "    return min(q, 1.0 - (1.0 / len(counts)))\n",
    "\n",
    "\n",
    "def compute_q_noisy_max_approx(counts, noise_eps):\n",
    "    \"\"\"Returns ~ Pr[outcome != winner].\n",
    "\n",
    "  Args:\n",
    "    counts: a list of scores\n",
    "    noise_eps: privacy parameter for noisy_max\n",
    "  Returns:\n",
    "    q: the probability that outcome is different from true winner.\n",
    "  \"\"\"\n",
    "    # For noisy max, we only get an upper bound.\n",
    "    # Pr[ j beats i*] \\leq (2+gap(j,i*))/ 4 exp(gap(j,i*)\n",
    "    # proof at http://mathoverflow.net/questions/66763/\n",
    "    # tight-bounds-on-probability-of-sum-of-laplace-random-variables\n",
    "    # This code uses an approximation that is faster and easier\n",
    "    # to get local sensitivity bound on.\n",
    "\n",
    "    winner = np.argmax(counts)\n",
    "    counts_normalized = noise_eps * (counts - counts[winner])\n",
    "    counts_rest = np.array([counts_normalized[i] for i in range(len(counts)) if i != winner])\n",
    "    gap = -max(counts_rest)\n",
    "    q = (len(counts) - 1) * (gap + 2.0) / (4.0 * math.exp(gap))\n",
    "    return min(q, 1.0 - (1.0 / len(counts)))\n",
    "\n",
    "\n",
    "def logmgf_exact(q, priv_eps, l):\n",
    "    \"\"\"Computes the logmgf value given q and privacy eps.\n",
    "\n",
    "  The bound used is the min of three terms. The first term is from\n",
    "  https://arxiv.org/pdf/1605.02065.pdf.\n",
    "  The second term is based on the fact that when event has probability (1-q) for\n",
    "  q close to zero, q can only change by exp(eps), which corresponds to a\n",
    "  much smaller multiplicative change in (1-q)\n",
    "  The third term comes directly from the privacy guarantee.\n",
    "  Args:\n",
    "    q: pr of non-optimal outcome\n",
    "    priv_eps: eps parameter for DP\n",
    "    l: moment to compute.\n",
    "  Returns:\n",
    "    Upper bound on logmgf\n",
    "  \"\"\"\n",
    "    if q < 0.5:\n",
    "        t_one = (1 - q) * math.pow((1 - q) / (1 - math.exp(priv_eps) * q), l)\n",
    "        t_two = q * math.exp(priv_eps * l)\n",
    "        t = t_one + t_two\n",
    "        try:\n",
    "            log_t = math.log(t)\n",
    "        except ValueError:\n",
    "            print(\"Got ValueError in math.log for values :\" + str((q, priv_eps, l, t)))\n",
    "            log_t = priv_eps * l\n",
    "    else:\n",
    "        log_t = priv_eps * l\n",
    "\n",
    "    return min(0.5 * priv_eps * priv_eps * l * (l + 1), log_t, priv_eps * l)\n",
    "\n",
    "\n",
    "def logmgf_from_counts(counts, noise_eps, l):\n",
    "    \"\"\"\n",
    "  ReportNoisyMax mechanism with noise_eps with 2*noise_eps-DP\n",
    "  in our setting where one count can go up by one and another\n",
    "  can go down by 1.\n",
    "  \"\"\"\n",
    "\n",
    "    q = compute_q_noisy_max(counts, noise_eps)\n",
    "    return logmgf_exact(q, 2.0 * noise_eps, l)\n",
    "\n",
    "\n",
    "def sens_at_k(counts, noise_eps, l, k):\n",
    "    \"\"\"Return sensitivity at distane k.\n",
    "\n",
    "  Args:\n",
    "    counts: an array of scores\n",
    "    noise_eps: noise parameter used\n",
    "    l: moment whose sensitivity is being computed\n",
    "    k: distance\n",
    "  Returns:\n",
    "    sensitivity: at distance k\n",
    "  \"\"\"\n",
    "    counts_sorted = sorted(counts, reverse=True)\n",
    "    if 0.5 * noise_eps * l > 1:\n",
    "        print(\"l too large to compute sensitivity\")\n",
    "        return 0\n",
    "    # Now we can assume that at k, gap remains positive\n",
    "    # or we have reached the point where logmgf_exact is\n",
    "    # determined by the first term and ind of q.\n",
    "    if counts[0] < counts[1] + k:\n",
    "        return 0\n",
    "    counts_sorted[0] -= k\n",
    "    counts_sorted[1] += k\n",
    "    val = logmgf_from_counts(counts_sorted, noise_eps, l)\n",
    "    counts_sorted[0] -= 1\n",
    "    counts_sorted[1] += 1\n",
    "    val_changed = logmgf_from_counts(counts_sorted, noise_eps, l)\n",
    "    return val_changed - val\n",
    "\n",
    "\n",
    "def smoothed_sens(counts, noise_eps, l, beta):\n",
    "    \"\"\"Compute beta-smooth sensitivity.\n",
    "\n",
    "  Args:\n",
    "    counts: array of scors\n",
    "    noise_eps: noise parameter\n",
    "    l: moment of interest\n",
    "    beta: smoothness parameter\n",
    "  Returns:\n",
    "    smooth_sensitivity: a beta smooth upper bound\n",
    "  \"\"\"\n",
    "    k = 0\n",
    "    smoothed_sensitivity = sens_at_k(counts, noise_eps, l, k)\n",
    "    while k < max(counts):\n",
    "        k += 1\n",
    "        sensitivity_at_k = sens_at_k(counts, noise_eps, l, k)\n",
    "        smoothed_sensitivity = max(smoothed_sensitivity, math.exp(-beta * k) * sensitivity_at_k)\n",
    "        if sensitivity_at_k == 0.0:\n",
    "            break\n",
    "    return smoothed_sensitivity\n",
    "\n",
    "\n",
    "def perform_analysis(teacher_preds, indices, noise_eps, delta=1e-5, moments=8, beta=0.09):\n",
    "    \"\"\"\"Performs PATE analysis on predictions from teachers and combined predictions for student.\n",
    "\n",
    "    Args:\n",
    "        teacher_preds: a numpy array of dim (num_teachers x num_examples). Each value corresponds to the\n",
    "            index of the label which a teacher gave for a specific example\n",
    "        indices: a numpy array of dim (num_examples) of aggregated examples which were aggregated using\n",
    "            the noisy max mechanism.\n",
    "        noise_eps: the epsilon level used to create the indices\n",
    "        delta: the desired level of delta\n",
    "        moments: the number of moments to track (see the paper)\n",
    "        beta: a smoothing parameter (see the paper)\n",
    "    Returns:\n",
    "        tuple: first value is the data dependent epsilon, then the data independent epsilon\n",
    "    \"\"\"\n",
    "\n",
    "    num_teachers, num_examples = teacher_preds.shape\n",
    "    _num_examples = indices.shape[0]\n",
    "    labels = set(list(teacher_preds.flatten()))\n",
    "    num_labels = len(labels)\n",
    "\n",
    "    assert num_examples == _num_examples\n",
    "\n",
    "    counts_mat = np.zeros((num_examples, num_labels))\n",
    "\n",
    "    for i in range(num_examples):\n",
    "        for j in range(num_teachers):\n",
    "            counts_mat[i, int(teacher_preds[j, i])] += 1\n",
    "\n",
    "    l_list = 1.0 + np.array(range(moments))\n",
    "\n",
    "    total_log_mgf_nm = np.array([0.0 for _ in l_list])\n",
    "    total_ss_nm = np.array([0.0 for _ in l_list])\n",
    "\n",
    "    for i in indices:\n",
    "\n",
    "        total_log_mgf_nm += np.array(\n",
    "            [logmgf_from_counts(counts_mat[i], noise_eps, l) for l in l_list]\n",
    "        )\n",
    "\n",
    "        total_ss_nm += np.array([smoothed_sens(counts_mat[i], noise_eps, l, beta) for l in l_list])\n",
    "\n",
    "    # We want delta = exp(alpha - eps l).\n",
    "    # Solving gives eps = (alpha - ln (delta))/l\n",
    "\n",
    "    eps_list_nm = (total_log_mgf_nm - math.log(delta)) / l_list\n",
    "\n",
    "    # print(\"Epsilons (Noisy Max): \" + str(eps_list_nm))\n",
    "    # print(\"Smoothed sensitivities (Noisy Max): \" + str(total_ss_nm / l_list))\n",
    "\n",
    "    # If beta < eps / 2 ln (1/delta), then adding noise Lap(1) * 2 SS/eps\n",
    "    # is eps,delta DP\n",
    "    # Also if beta < eps / 2(gamma +1), then adding noise 2(gamma+1) SS eta / eps\n",
    "    # where eta has density proportional to 1 / (1+|z|^gamma) is eps-DP\n",
    "    # Both from Corolloary 2.4 in\n",
    "    # http://www.cse.psu.edu/~ads22/pubs/NRS07/NRS07-full-draft-v1.pdf\n",
    "    # Print the first one's scale\n",
    "\n",
    "    ss_eps = 2.0 * beta * math.log(1 / delta)\n",
    "    ss_scale = 2.0 / ss_eps\n",
    "    # print(\"To get an \" + str(ss_eps) + \"-DP estimate of epsilon, \")\n",
    "    # print(\"..add noise ~ \" + str(ss_scale))\n",
    "    # print(\"... times \" + str(total_ss_nm / l_list))\n",
    "    # print(\"Epsilon = \" + str(min(eps_list_nm)) + \".\")\n",
    "    if min(eps_list_nm) == eps_list_nm[-1]:\n",
    "        print(\n",
    "            \"Warning: May not have used enough values of l. Increase 'moments' variable and run again.\"\n",
    "        )\n",
    "\n",
    "    # Data independent bound, as mechanism is\n",
    "    # 2*noise_eps DP.\n",
    "    data_ind_log_mgf = np.array([0.0 for _ in l_list])\n",
    "    data_ind_log_mgf += num_examples * np.array(\n",
    "        [logmgf_exact(1.0, 2.0 * noise_eps, l) for l in l_list]\n",
    "    )\n",
    "\n",
    "    data_ind_eps_list = (data_ind_log_mgf - math.log(delta)) / l_list\n",
    "    # print(\"Data independent bound = \" + str(min(data_ind_eps_list)) + \".\")\n",
    "\n",
    "    return min(eps_list_nm), min(data_ind_eps_list)\n",
    "\n",
    "\n",
    "def tensors_to_literals(tensor_list):\n",
    "    \"\"\"Converts list of torch tensors to list of integers/floats. Fix for not having the functionality which converts list of tensors to tensors\n",
    "    \n",
    "       Args:\n",
    "           \n",
    "           tensor_list[List]: List of torch tensors\n",
    "           \n",
    "       Returns:\n",
    "           \n",
    "           literal_list[List]: List of floats/integers\n",
    "           \n",
    "    \"\"\"\n",
    "\n",
    "    literal_list = []\n",
    "\n",
    "    for tensor in tensor_list:\n",
    "        literal_list.append(tensor.item())\n",
    "\n",
    "    return literal_list\n",
    "\n",
    "\n",
    "def logmgf_exact_torch(q, priv_eps, l):\n",
    "    \"\"\"Computes the logmgf value given q and privacy eps.\n",
    "       The bound used is the min of three terms. The first term is from\n",
    "       https://arxiv.org/pdf/1605.02065.pdf.\n",
    "       The second term is based on the fact that when event has probability (1-q) for\n",
    "       q close to zero, q can only change by exp(eps), which corresponds to a\n",
    "       much smaller multiplicative change in (1-q)\n",
    "       The third term comes directly from the privacy guarantee.\n",
    "       Args:\n",
    "            q: pr of non-optimal outcome\n",
    "            priv_eps: eps parameter for DP\n",
    "            l: moment to compute.\n",
    "       Returns:\n",
    "            Upper bound on logmgf\n",
    "      \"\"\"\n",
    "    if q < 0.5:\n",
    "        t_one = (1 - q) * math.pow((1 - q) / (1 - math.exp(priv_eps) * q), l)\n",
    "        t_two = q * math.exp(priv_eps * l)\n",
    "        t = t_one + t_two\n",
    "        try:\n",
    "\n",
    "            log_t = math.log(t)\n",
    "\n",
    "        except ValueError:\n",
    "\n",
    "            print(\"Got ValueError in math.log for values :\" + str((q, priv_eps, l, t)))\n",
    "            log_t = priv_eps * l\n",
    "    else:\n",
    "\n",
    "        log_t = priv_eps * l\n",
    "\n",
    "    return min(0.5 * priv_eps * priv_eps * l * (l + 1), log_t, priv_eps * l)\n",
    "\n",
    "\n",
    "def compute_q_noisy_max_torch(counts, noise_eps):\n",
    "    \"\"\"Returns ~ Pr[outcome != winner].\n",
    "       Args:\n",
    "           \n",
    "          counts: a list of scores\n",
    "          noise_eps: privacy parameter for noisy_max\n",
    "          \n",
    "       Returns:\n",
    "           \n",
    "          q: the probability that outcome is different from true winner.\n",
    "          \n",
    "    \"\"\"\n",
    "\n",
    "    if type(counts) != torch.tensor:\n",
    "\n",
    "        counts = torch.tensor(tensors_to_literals(counts), dtype=torch.float)\n",
    "\n",
    "    _, winner = counts.max(0)\n",
    "    counts_normalized = noise_eps * (\n",
    "        torch.tensor(counts, dtype=torch.float) - torch.tensor(counts[winner], dtype=torch.float)\n",
    "    )\n",
    "\n",
    "    counts_normalized = tensors_to_literals(counts_normalized)\n",
    "    counts_rest = torch.tensor(\n",
    "        [counts_normalized[i] for i in range(len(counts)) if i != winner], dtype=torch.float\n",
    "    )\n",
    "    q = 0.0\n",
    "\n",
    "    index = 0\n",
    "    for c in counts_rest:\n",
    "\n",
    "        gap = -c\n",
    "        q += (gap + 2.0) / (4.0 * math.exp(gap))\n",
    "\n",
    "        index += 1\n",
    "\n",
    "    return min(q, 1.0 - (1.0 / len(counts)))\n",
    "\n",
    "\n",
    "def logmgf_from_counts_torch(counts, noise_eps, l):\n",
    "\n",
    "    \"\"\"\n",
    "        ReportNoisyMax mechanism with noise_eps with 2*noise_eps-DP\n",
    "        in our setting where one count can go up by one and another\n",
    "        can go down by 1.\n",
    "    \"\"\"\n",
    "\n",
    "    q = compute_q_noisy_max_torch(counts, noise_eps)\n",
    "\n",
    "    return logmgf_exact_torch(q, 2.0 * noise_eps, l)\n",
    "\n",
    "\n",
    "def sens_at_k_torch(counts, noise_eps, l, k):\n",
    "\n",
    "    \"\"\"Return sensitivity at distane k.\n",
    "      Args:\n",
    "        \n",
    "          counts: an array of scores\n",
    "          noise_eps: noise parameter used\n",
    "          l: moment whose sensitivity is being computed\n",
    "          k: distance\n",
    "      Returns:\n",
    "         sensitivity: at distance k\n",
    "     \"\"\"\n",
    "\n",
    "    counts_sorted = sorted(counts, reverse=True)\n",
    "\n",
    "    if 0.5 * noise_eps * l > 1:\n",
    "\n",
    "        print(\"l too large to compute sensitivity\")\n",
    "        return 0\n",
    "\n",
    "    if counts[0] < counts[1] + k:\n",
    "\n",
    "        return 0\n",
    "\n",
    "    counts_sorted[0] -= k\n",
    "    counts_sorted[1] += k\n",
    "    val = logmgf_from_counts_torch(counts_sorted, noise_eps, l)\n",
    "    counts_sorted[0] -= 1\n",
    "    counts_sorted[1] += 1\n",
    "    val_changed = logmgf_from_counts_torch(counts_sorted, noise_eps, l)\n",
    "    return val_changed - val\n",
    "\n",
    "\n",
    "def smooth_sens_torch(counts, noise_eps, l, beta):\n",
    "\n",
    "    \"\"\"Compute beta-smooth sensitivity.\n",
    "    \n",
    "     Args:\n",
    "         counts: array of scors\n",
    "         noise_eps: noise parameter\n",
    "         l: moment of interest\n",
    "         beta: smoothness parameter\n",
    "     Returns:\n",
    "         smooth_sensitivity: a beta smooth upper bound\n",
    "     \"\"\"\n",
    "\n",
    "    k = 0\n",
    "    smoothed_sensitivity = sens_at_k_torch(counts, noise_eps, l, k)\n",
    "\n",
    "    while k < max(counts):\n",
    "\n",
    "        k += 1\n",
    "        sensitivity_at_k = sens_at_k_torch(counts, noise_eps, l, k)\n",
    "        smoothed_sensitivity = max(smoothed_sensitivity, math.exp(-beta * k) * sensitivity_at_k)\n",
    "        if sensitivity_at_k == 0.0:\n",
    "            break\n",
    "\n",
    "    return smoothed_sensitivity\n",
    "\n",
    "\n",
    "def perform_analysis_torch(preds, indices, noise_eps=0.1, delta=1e-5, moments=8, beta=0.09):\n",
    "    \"\"\"Performs PATE analysis on predictions from teachers and combined predictions for student.\n",
    "    Args:\n",
    "        teacher_preds: a torch tensor of dim (num_teachers x num_examples). Each value corresponds to the\n",
    "            index of the label which a teacher gave for a specific example\n",
    "        indices: a torch tensor of dim (num_examples) of aggregated examples which were aggregated using\n",
    "            the noisy max mechanism.\n",
    "        noise_eps: the epsilon level used to create the indices\n",
    "        delta: the desired level of delta\n",
    "        moments: the number of moments to track (see the paper)\n",
    "        beta: a smoothing parameter (see the paper)\n",
    "    Returns:\n",
    "        tuple: first value is the data dependent epsilon, then the data independent epsilon\n",
    "    \"\"\"\n",
    "\n",
    "    num_teachers, num_examples = preds.shape\n",
    "    _num_examples = indices.shape[0]\n",
    "\n",
    "    assert num_examples == _num_examples\n",
    "\n",
    "    labels = list(preds.flatten())\n",
    "    labels = set([tensor.item() for tensor in labels])\n",
    "    num_labels = len(labels)\n",
    "\n",
    "    counts_mat = torch.zeros(num_examples, num_labels, dtype=torch.float32)\n",
    "\n",
    "    for i in range(num_examples):\n",
    "\n",
    "        for j in range(num_teachers):\n",
    "\n",
    "            counts_mat[i, int(preds[j, i])] += 1\n",
    "\n",
    "    l_list = 1 + torch.tensor(range(moments), dtype=torch.float)\n",
    "\n",
    "    total_log_mgf_nm = torch.tensor([0.0 for _ in l_list], dtype=torch.float)\n",
    "    total_ss_nm = torch.tensor([0.0 for _ in l_list], dtype=torch.float)\n",
    "\n",
    "    for i in indices:\n",
    "\n",
    "        total_log_mgf_nm += torch.tensor(\n",
    "            [logmgf_from_counts_torch(counts_mat[i].clone(), noise_eps, l) for l in l_list]\n",
    "        )\n",
    "\n",
    "        total_ss_nm += torch.tensor(\n",
    "            [smooth_sens_torch(counts_mat[i].clone(), noise_eps, l, beta) for l in l_list],\n",
    "            dtype=torch.float,\n",
    "        )\n",
    "\n",
    "    eps_list_nm = (total_log_mgf_nm - math.log(delta)) / l_list\n",
    "    ss_eps = 2.0 * beta * math.log(1 / delta)\n",
    "    ss_scale = 2.0 / ss_eps\n",
    "    if min(eps_list_nm) == eps_list_nm[-1]:\n",
    "        print(\n",
    "            \"Warning: May not have used enough values of l. Increase 'moments' variable and run again.\"\n",
    "        )\n",
    "\n",
    "    data_ind_log_mgf = torch.tensor([0.0 for _ in l_list])\n",
    "    data_ind_log_mgf += num_examples * torch.tensor(\n",
    "        tensors_to_literals([logmgf_exact_torch(1.0, 2.0 * noise_eps, l) for l in l_list])\n",
    "    )\n",
    "\n",
    "    data_ind_eps_list = (data_ind_log_mgf - math.log(delta)) / l_list\n",
    "\n",
    "    return min(eps_list_nm), min(data_ind_eps_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PATE Analysis\n",
    "\n",
    "Perform PATE analysis and show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_dep_eps, data_ind_eps = perform_analysis(teacher_preds=preds, indices=student_labels, noise_eps=epsilon, delta=1e-5)\n",
    "print(\"Data Independent Epsilon:\", data_ind_eps)\n",
    "print(\"Data Dependent Epsilon:\", data_dep_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the student\n",
    "\n",
    "Now we will train the student with the aggregated teacher labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_loader(student_train_loader, labels):\n",
    "    for i, (data, _) in enumerate(iter(student_train_loader)):\n",
    "        yield data, torch.from_numpy(labels[i*len(data):(i+1)*len(data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model =ConvNet(channel=3, num_classes= 100,net_width=net_width, net_depth=net_depth, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling,im_size=(32,32))\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=0.001)\n",
    "epochs = 10\n",
    "student_model.to(device)\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "for e in range(epochs):\n",
    "    # Model in training mode, dropout is on\n",
    "    student_model.train()\n",
    "    train_loader = student_loader(student_train_loader, student_labels)\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        steps += 1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = student_model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if steps % 50 == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            student_model.eval()\n",
    "            with torch.no_grad():\n",
    "                for images, labels in student_test_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    log_ps = student_model(images)\n",
    "                    test_loss += criterion(log_ps, labels).item()\n",
    "                    \n",
    "                    # Accuracy\n",
    "                    ps = torch.exp(log_ps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "            student_model.train()\n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/len(student_train_loader)),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(student_test_loader)),\n",
    "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(student_test_loader)))\n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_model = models[99]\n",
    "t1_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    for images, labels in student_test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        log_ps = t1_model(images)\n",
    "        test_loss += criterion(log_ps, labels).item()\n",
    "\n",
    "        # Accuracy\n",
    "        ps = torch.exp(log_ps)\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "    t1_model.train()\n",
    "    print(\"Test Loss: {:.3f}.. \".format(test_loss),\n",
    "          \"Test Accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
