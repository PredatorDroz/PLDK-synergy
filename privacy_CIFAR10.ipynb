{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa60124c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fahim\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\fahim\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "C:\\Users\\fahim\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda: True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from sklearn.metrics import top_k_accuracy_score \n",
    "\n",
    "from utils import Bar, Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "import numpy as np\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "print(f'Cuda: {use_cuda}')\n",
    "\n",
    "# manualSeed = random.randint(1, 10000)\n",
    "manualSeed = 0\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed_all(manualSeed)\n",
    "\n",
    "best_acc = 0  # best test accuracy\n",
    "\n",
    "if sys.platform.startswith('linux'):\n",
    "    LINUX = True\n",
    "else:\n",
    "    LINUX = False\n",
    "\n",
    "if LINUX:\n",
    "    DATA_ROOT = r\"/home/abedikhh/data/sets/\"\n",
    "    RESULTS_ROOT = r\"/home/abedikhh/results/privacy_reg/\"\n",
    "    LOG_ROOT = r\"/home/abedikhh/logs/privacy_reg/\"\n",
    "else:\n",
    "    DATA_ROOT = r\"F:\\Other\\data\"\n",
    "    RESULTS_ROOT = r\"F:\\Other\\privacy_reg\\results\"\n",
    "    LOG_ROOT = r\"F:\\logs\"\n",
    "# %%\n",
    "NUM_WORKERS = 0  # 0 for debugging as script?\n",
    "\n",
    "# dataset = 'cifar10'\n",
    "dataset = 'cifar100'\n",
    "\n",
    "LR = 0.05\n",
    "EPOCHS = 400\n",
    "\n",
    "train_batch = 100\n",
    "test_batch = 100\n",
    "state = {'lr': LR}\n",
    "\n",
    "checkpoint_path = os.path.join(RESULTS_ROOT, f'checkpoints_{dataset}_alexnetdefense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "023c40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ResNet in PyTorch.\n",
    "\n",
    "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
    "\n",
    "Reference:\n",
    "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
    "'''\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=100):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3,4,6,3])\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3,4,6,3])\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3,4,23,3])\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3,8,36,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e479d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"resnext in pytorch\n",
    "[1] Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, Kaiming He.\n",
    "    Aggregated Residual Transformations for Deep Neural Networks\n",
    "    https://arxiv.org/abs/1611.05431\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#only implements ResNext bottleneck c\n",
    "\n",
    "\n",
    "#\"\"\"This strategy exposes a new dimension, which we call “cardinality”\n",
    "#(the size of the set of transformations), as an essential factor\n",
    "#in addition to the dimensions of depth and width.\"\"\"\n",
    "CARDINALITY = 32\n",
    "DEPTH = 4\n",
    "BASEWIDTH = 64\n",
    "\n",
    "#\"\"\"The grouped convolutional layer in Fig. 3(c) performs 32 groups\n",
    "#of convolutions whose input and output channels are 4-dimensional.\n",
    "#The grouped convolutional layer concatenates them as the outputs\n",
    "#of the layer.\"\"\"\n",
    "\n",
    "class ResNextBottleNeckC(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super().__init__()\n",
    "\n",
    "        C = CARDINALITY #How many groups a feature map was splitted into\n",
    "\n",
    "        #\"\"\"We note that the input/output width of the template is fixed as\n",
    "        #256-d (Fig. 3), We note that the input/output width of the template\n",
    "        #is fixed as 256-d (Fig. 3), and all widths are dou- bled each time\n",
    "        #when the feature map is subsampled (see Table 1).\"\"\"\n",
    "        D = int(DEPTH * out_channels / BASEWIDTH) #number of channels per group\n",
    "        self.split_transforms = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, C * D, kernel_size=1, groups=C, bias=False),\n",
    "            nn.BatchNorm2d(C * D),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(C * D, C * D, kernel_size=3, stride=stride, groups=C, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(C * D),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(C * D, out_channels * 4, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * 4),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * 4:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * 4, stride=stride, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * 4)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(self.split_transforms(x) + self.shortcut(x))\n",
    "\n",
    "class ResNext(nn.Module):\n",
    "\n",
    "    def __init__(self, block, num_blocks, class_names=100):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.conv2 = self._make_layer(block, num_blocks[0], 64, 1)\n",
    "        self.conv3 = self._make_layer(block, num_blocks[1], 128, 2)\n",
    "        self.conv4 = self._make_layer(block, num_blocks[2], 256, 2)\n",
    "        self.conv5 = self._make_layer(block, num_blocks[3], 512, 2)\n",
    "        self.avg = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(512 * 4, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.avg(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x= self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, block, num_block, out_channels, stride):\n",
    "        \"\"\"Building resnext block\n",
    "        Args:\n",
    "            block: block type(default resnext bottleneck c)\n",
    "            num_block: number of blocks per layer\n",
    "            out_channels: output channels per block\n",
    "            stride: block stride\n",
    "        Returns:\n",
    "            a resnext layer\n",
    "        \"\"\"\n",
    "        strides = [stride] + [1] * (num_block - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * 4\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "def resnext50():\n",
    "    \"\"\" return a resnext50(c32x4d) network\n",
    "    \"\"\"\n",
    "    return ResNext(ResNextBottleNeckC, [3, 4, 6, 3])\n",
    "\n",
    "def resnext101():\n",
    "    \"\"\" return a resnext101(c32x4d) network\n",
    "    \"\"\"\n",
    "    return ResNext(ResNextBottleNeckC, [3, 4, 23, 3])\n",
    "\n",
    "def resnext152():\n",
    "    \"\"\" return a resnext101(c32x4d) network\n",
    "    \"\"\"\n",
    "    return ResNext(ResNextBottleNeckC, [3, 4, 36, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "255ad237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# __all__ = ['densenet']\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, inplanes, expansion=4, growthRate=12, dropRate=0):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        planes = expansion * growthRate\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, growthRate, kernel_size=3, \n",
    "                               padding=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropRate = dropRate\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        if self.dropRate > 0:\n",
    "            out = F.dropout(out, p=self.dropRate, training=self.training)\n",
    "\n",
    "        out = torch.cat((x, out), 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, inplanes, expansion=1, growthRate=12, dropRate=0):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        planes = expansion * growthRate\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.conv1 = nn.Conv2d(inplanes, growthRate, kernel_size=3, \n",
    "                               padding=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropRate = dropRate\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "        if self.dropRate > 0:\n",
    "            out = F.dropout(out, p=self.dropRate, training=self.training)\n",
    "\n",
    "        out = torch.cat((x, out), 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, inplanes, outplanes):\n",
    "        super(Transition, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.conv1 = nn.Conv2d(inplanes, outplanes, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "#it was 12 (growth rate) now 19\n",
    "    def __init__(self, depth=22, block=Bottleneck, \n",
    "        dropRate=0, num_classes=100, growthRate=19, compressionRate=2):\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        assert (depth - 4) % 3 == 0, 'depth should be 3n+4'\n",
    "        n = (depth - 4) / 3 if block == BasicBlock else (depth - 4) // 6\n",
    "\n",
    "        self.growthRate = growthRate\n",
    "        self.dropRate = dropRate\n",
    "\n",
    "        # self.inplanes is a global variable used across multiple\n",
    "        # helper functions\n",
    "        self.inplanes = growthRate * 2 \n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, padding=1,\n",
    "                               bias=False)\n",
    "        self.dense1 = self._make_denseblock(block, n)\n",
    "        self.trans1 = self._make_transition(compressionRate)\n",
    "        self.dense2 = self._make_denseblock(block, n)\n",
    "        self.trans2 = self._make_transition(compressionRate)\n",
    "        self.dense3 = self._make_denseblock(block, n)\n",
    "        self.bn = nn.BatchNorm2d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.avgpool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(self.inplanes, num_classes)\n",
    "\n",
    "        # Weight initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_denseblock(self, block, blocks):\n",
    "        layers = []\n",
    "        for i in range(blocks):\n",
    "            # Currently we fix the expansion ratio as the default value\n",
    "            layers.append(block(self.inplanes, growthRate=self.growthRate, dropRate=self.dropRate))\n",
    "            self.inplanes += self.growthRate\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_transition(self, compressionRate):\n",
    "        inplanes = self.inplanes\n",
    "        outplanes = int(math.floor(self.inplanes // compressionRate))\n",
    "        self.inplanes = outplanes\n",
    "        return Transition(inplanes, outplanes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.trans1(self.dense1(x)) \n",
    "        x = self.trans2(self.dense2(x)) \n",
    "        x = self.dense3(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c8cbdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% AlexNet Module\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=(5, 5), padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def alexnet(**kwargs):\n",
    "    r\"\"\"AlexNet model architecture from the\n",
    "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
    "    \"\"\"\n",
    "    model = AlexNet(**kwargs)\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abc5a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Inference Attack HZ Class\n",
    "\n",
    "\n",
    "class InferenceAttack_HZ(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        super(InferenceAttack_HZ, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(self.num_classes, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.labels = nn.Sequential(\n",
    "            nn.Linear(num_classes, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.combine = nn.Sequential(\n",
    "            nn.Linear(64 * 2, 256),\n",
    "\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "\n",
    "        for key in self.state_dict():\n",
    "            print(f'\\t {key}')\n",
    "            if key.split('.')[-1] == 'weight':\n",
    "                nn.init.normal_(self.state_dict()[key], std=0.01)\n",
    "\n",
    "            elif key.split('.')[-1] == 'bias':\n",
    "                self.state_dict()[key][...] = 0\n",
    "\n",
    "        self.output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "\n",
    "        out_x = self.features(x)\n",
    "        out_l = self.labels(labels)\n",
    "\n",
    "        is_member = self.combine(torch.cat((out_x, out_l), 1))\n",
    "\n",
    "        return self.output(is_member)\n",
    "\n",
    "\n",
    "# %% Status Func\n",
    "\n",
    "def report_str(batch_idx, data_time, batch_time, losses, top1, top5):\n",
    "    batch = f'({batch_idx:4d})'\n",
    "    time = f'Data: {data_time:.2f}s | Batch: {batch_time:.2f}s'\n",
    "    loss_ac1 = f'Loss: {losses:.3f} | Top1: {top1 * 100:.2f}%'\n",
    "\n",
    "    res = f'{batch} {time} || {loss_ac1}'\n",
    "\n",
    "    if top5 is None:\n",
    "        return res\n",
    "    else:\n",
    "        return res + f' | Top5: {top5 * 100:.2f}%'\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eb9f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% train_privately\n",
    "#alpha=0.9\n",
    "def train_privately(trainloader, model, inference_model, criterion, optimizer, use_cuda, num_batches=10000, alpha=1.9):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    inference_model.eval()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    end = time.time()\n",
    "\n",
    "    first_id = -1\n",
    "    for batch_idx, (inputs, targets) in trainloader:\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        if first_id == -1:\n",
    "            first_id = batch_idx\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda(non_blocking=True)\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        one_hot_tr = torch.from_numpy((np.zeros((outputs.size(0), num_classes)) - 1)).cuda().type(torch.float)\n",
    "\n",
    "        target_one_hot_tr = one_hot_tr.scatter_(1, targets.type(torch.int64).view([-1, 1]).data, 1)\n",
    "\n",
    "        infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
    "\n",
    "        inference_output = inference_model(outputs, infer_input_one_hot)\n",
    "        # print (inference_output.mean())\n",
    "        loss = criterion(outputs, targets) + alpha * ((inference_output - 1.0).pow(2).mean())\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        # prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "\n",
    "        prec1 = top_k_accuracy_score(y_true=targets.data.cpu(), y_score=outputs.data.cpu(),\n",
    "                                     k=1, labels=range(num_classes))\n",
    "\n",
    "        prec5 = top_k_accuracy_score(y_true=targets.data.cpu(), y_score=outputs.data.cpu(),\n",
    "                                     k=5, labels=range(num_classes))\n",
    "\n",
    "        losses.update(loss.data.item(), inputs.size(0))\n",
    "        top1.update(prec1, inputs.size(0))\n",
    "        top5.update(prec5, inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(report_str(batch_idx + 1, data_time.avg, batch_time.avg, losses.avg, top1.avg, top5.avg))\n",
    "\n",
    "        if batch_idx - first_id >= num_batches:\n",
    "            break\n",
    "\n",
    "    return losses.avg, top1.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "129cdc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% train\n",
    "def train(trainloader, model, criterion, optimizer, use_cuda):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    end = time.time()\n",
    "\n",
    "    bar = Bar('Processing', max=len(trainloader))\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda(non_blocking=True)\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        # prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "\n",
    "        prec1 = top_k_accuracy_score(y_true=targets.data.cpu(), y_score=outputs.data.cpu(),\n",
    "                                     k=1, labels=range(num_classes))\n",
    "\n",
    "        prec5 = top_k_accuracy_score(y_true=targets.data.cpu(), y_score=outputs.data.cpu(),\n",
    "                                     k=5, labels=range(num_classes))\n",
    "\n",
    "        losses.update(loss.data.item(), inputs.size(0))\n",
    "        top1.update(prec1, inputs.size(0))\n",
    "        top5.update(prec5, inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(report_str(batch_idx + 1, data_time.avg, batch_time.avg, losses.avg, top1.avg, top5.avg))\n",
    "\n",
    "        return losses.avg, top1.avg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aace841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% test\n",
    "def test(testloader, model, criterion, use_cuda):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs = inputs.cuda()\n",
    "                targets = targets.cuda()\n",
    "\n",
    "            # compute output\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            # prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "            prec1 = top_k_accuracy_score(y_true=targets.data.cpu(), y_score=outputs.data.cpu(),\n",
    "                                         k=1, labels=range(num_classes))\n",
    "\n",
    "            prec5 = top_k_accuracy_score(y_true=targets.data.cpu(), y_score=outputs.data.cpu(), k=5,\n",
    "                                         labels=range(num_classes))\n",
    "            losses.update(loss.data.item(), inputs.size(0))\n",
    "            top1.update(prec1, inputs.size(0))\n",
    "            top5.update(prec5, inputs.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            # plot progress\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(report_str(batch_idx + 1, data_time.avg, batch_time.avg, losses.avg, top1.avg, top5.avg))\n",
    "\n",
    "    return losses.avg, top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a451fa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% privacy_train\n",
    "def privacy_train(trainloader, model, inference_model, criterion, optimizer, use_cuda, num_batchs=1000):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    mtop1_a = AverageMeter()\n",
    "    mtop5_a = AverageMeter()\n",
    "\n",
    "    inference_model.train()\n",
    "    model.eval()\n",
    "    # switch to evaluate mode\n",
    "\n",
    "    end = time.time()\n",
    "    first_id = -1\n",
    "    for batch_idx, ((tr_input, tr_target), (te_input, te_target)) in trainloader:\n",
    "        # measure data loading time\n",
    "        if first_id == -1:\n",
    "            first_id = batch_idx\n",
    "\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            tr_input = tr_input.cuda()\n",
    "            te_input = te_input.cuda()\n",
    "            tr_target = tr_target.cuda()\n",
    "            te_target = te_target.cuda()\n",
    "\n",
    "        v_tr_input = torch.autograd.Variable(tr_input)\n",
    "        v_te_input = torch.autograd.Variable(te_input)\n",
    "        v_tr_target = torch.autograd.Variable(tr_target)\n",
    "        v_te_target = torch.autograd.Variable(te_target)\n",
    "\n",
    "        # compute output\n",
    "        model_input = torch.cat((v_tr_input, v_te_input))\n",
    "\n",
    "        pred_outputs = model(model_input)\n",
    "        #y_hat\n",
    "\n",
    "        infer_input = torch.cat((v_tr_target, v_te_target))\n",
    "        #(y_hat)\n",
    "\n",
    "        # TODO fix\n",
    "        # mtop1, mtop5 = accuracy(pred_outputs.data, infer_input.data, topk=(1, 5))\n",
    "        mtop1 = top_k_accuracy_score(y_true=infer_input.data.cpu(), y_score=pred_outputs.data.cpu(),\n",
    "                                     k=1, labels=range(num_classes))\n",
    "\n",
    "        mtop5 = top_k_accuracy_score(y_true=infer_input.data.cpu(), y_score=pred_outputs.data.cpu(),\n",
    "                                     k=5, labels=range(num_classes))\n",
    "\n",
    "        mtop1_a.update(mtop1, model_input.size(0))\n",
    "        mtop5_a.update(mtop5, model_input.size(0))\n",
    "\n",
    "        one_hot_tr = torch.from_numpy((np.zeros((infer_input.size(0), num_classes)) - 1)).cuda().type(torch.float)\n",
    "        target_one_hot_tr = one_hot_tr.scatter_(1, infer_input.type(torch.int64).view([-1, 1]).data, 1)\n",
    "\n",
    "        infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
    "        #ONE_hot y_hat\n",
    "\n",
    "        attack_model_input = pred_outputs  # torch.cat((pred_outputs,infer_input_one_hot),1)\n",
    "        member_output = inference_model(attack_model_input, infer_input_one_hot)\n",
    "        #inf_model(y,y_hat)\n",
    "        #member->?0/1\n",
    "\n",
    "        is_member_labels = torch.from_numpy(\n",
    "            np.reshape(\n",
    "                np.concatenate((np.zeros(v_tr_input.size(0)), np.ones(v_te_input.size(0)))),\n",
    "                [-1, 1]\n",
    "            )\n",
    "        ).cuda()\n",
    "\n",
    "        v_is_member_labels = torch.autograd.Variable(is_member_labels).type(torch.float)\n",
    "        #true_labels\n",
    "\n",
    "        loss = criterion(member_output, v_is_member_labels)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = np.mean((member_output.data.cpu().numpy() > 0.5) == v_is_member_labels.data.cpu().numpy())\n",
    "        losses.update(loss.data.item(), model_input.size(0))\n",
    "        top1.update(prec1, model_input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if batch_idx - first_id > num_batchs:\n",
    "            break\n",
    "\n",
    "        # plot progress\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(report_str(batch_idx, data_time.avg, batch_time.avg, losses.avg, top1.avg, None))\n",
    "\n",
    "    return losses.avg, top1.avg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7033df7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% privacy_test\n",
    "def privacy_test(trainloader, model, inference_model, criterion, optimizer, use_cuda, num_batchs=1000):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    mtop1_a = AverageMeter()\n",
    "    mtop5_a = AverageMeter()\n",
    "\n",
    "    inference_model.eval()\n",
    "    model.eval()\n",
    "    # switch to evaluate mode\n",
    "\n",
    "    end = time.time()\n",
    "    first_id = -1\n",
    "    for batch_idx, ((tr_input, tr_target), (te_input, te_target)) in trainloader:\n",
    "        # measure data loading time\n",
    "        if first_id == -1:\n",
    "            first_id = batch_idx\n",
    "\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            tr_input = tr_input.cuda()\n",
    "            te_input = te_input.cuda()\n",
    "            tr_target = tr_target.cuda()\n",
    "            te_target = te_target.cuda()\n",
    "\n",
    "        v_tr_input = torch.autograd.Variable(tr_input)\n",
    "        v_te_input = torch.autograd.Variable(te_input)\n",
    "        v_tr_target = torch.autograd.Variable(tr_target)\n",
    "        v_te_target = torch.autograd.Variable(te_target)\n",
    "\n",
    "        # compute output\n",
    "        model_input = torch.cat((v_tr_input, v_te_input))\n",
    "\n",
    "        pred_outputs = model(model_input)\n",
    "\n",
    "        infer_input = torch.cat((v_tr_target, v_te_target))\n",
    "\n",
    "        # mtop1, mtop5 = accuracy(pred_outputs.data, infer_input.data, topk=(1, 5))\n",
    "        mtop1 = top_k_accuracy_score(y_true=pred_outputs.data.cpu(), y_score=infer_input.data.cpu(), k=1,\n",
    "                                     labels=range(num_classes))\n",
    "        mtop5 = top_k_accuracy_score(y_true=pred_outputs.data.cpu(), y_score=infer_input.data.cpu(), k=5,\n",
    "                                     labels=range(num_classes))\n",
    "\n",
    "        mtop1_a.update(mtop1, model_input.size(0))\n",
    "        mtop5_a.update(mtop5, model_input.size(0))\n",
    "\n",
    "        one_hot_tr = torch.from_numpy((np.zeros((infer_input.size(0), num_classes)) - 1)).cuda().type(torch.float)\n",
    "        target_one_hot_tr = one_hot_tr.scatter_(1, infer_input.type(torch.int64).view([-1, 1]).data, 1)\n",
    "\n",
    "        infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
    "\n",
    "        attack_model_input = pred_outputs  # torch.cat((pred_outputs,infer_input_one_hot),1)\n",
    "        member_output = inference_model(attack_model_input, infer_input_one_hot)\n",
    "\n",
    "        is_member_labels = torch.from_numpy(\n",
    "            np.reshape(\n",
    "                np.concatenate((np.zeros(v_tr_input.size(0)), np.ones(v_te_input.size(0)))),\n",
    "                [-1, 1]\n",
    "            )\n",
    "        ).cuda()\n",
    "\n",
    "        v_is_member_labels = torch.autograd.Variable(is_member_labels).type(torch.float)\n",
    "\n",
    "        loss = criterion(member_output, v_is_member_labels)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = np.mean((member_output.data.cpu().numpy() > 0.5) == v_is_member_labels.data.cpu().numpy())\n",
    "        losses.update(loss.data.item(), model_input.size(0))\n",
    "        top1.update(prec1, model_input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if batch_idx - first_id >= num_batchs:\n",
    "            break\n",
    "\n",
    "        # plot progress\n",
    "        # if batch_idx%10==0:\n",
    "        #     print(report_str(batch_idx + 1, data_time.avg, batch_time.avg, losses.avg, top1.avg, None))\n",
    "        #     print  ('({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | | Loss: {loss:.4f} | top1: {top1: .4f} '.format(\n",
    "        #             batch=batch_idx ,\n",
    "        #             size=len(trainloader),\n",
    "        #             data=data_time.avg,\n",
    "        #             bt=batch_time.avg,\n",
    "        #             loss=losses.avg,\n",
    "        #             top1=top1.avg,\n",
    "        #             ))\n",
    "\n",
    "    return losses.avg, top1.avg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4490711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset cifar10\n"
     ]
    }
   ],
   "source": [
    "# %% checkpoint, adjust LR\n",
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    global state\n",
    "    if epoch in [20, 40]:\n",
    "        state['lr'] *= 0.1\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = state['lr']\n",
    "\n",
    "\n",
    "def save_checkpoint_adversary(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_adversary_best.pth.tar'))\n",
    "\n",
    "\n",
    "# %% Dataset\n",
    "dataset ='cifar10'\n",
    "print('==> Preparing dataset %s' % dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5822b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f50457",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20784/3213683779.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnext\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresnext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'cifar10'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtrain_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m125.307\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m122.950\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m113.865\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtrain_std\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m62.993\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m62.089\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m66.705\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import model.resnet as resnet\n",
    "import model.resnext as resnext\n",
    "\n",
    "if dataset == 'cifar10':\n",
    "    train_mean = np.array([125.307, 122.950, 113.865])\n",
    "    train_std = np.array([62.993, 62.089, 66.705])\n",
    "    test_mean = np.array([126.025, 123.708, 114.854])\n",
    "    test_std = np.array([62.896, 61.937, 66.706])\n",
    "else:\n",
    "    train_ds = datasets.CIFAR100(os.path.join(DATA_ROOT, 'cifar100'), train=True, download=True)\n",
    "    test_ds = datasets.CIFAR100(os.path.join(DATA_ROOT, 'cifar100'), train=False, download=True)\n",
    "\n",
    "    _data_train = np.concatenate([np.array(train_ds[i][0]) for i in range(len(train_ds))])\n",
    "    _data_test = np.concatenate([np.array(test_ds[i][0]) for i in range(len(test_ds))])\n",
    "\n",
    "    train_mean = _data_train.mean(axis=(0, 1))\n",
    "    train_std = _data_train.std(axis=(0, 1))\n",
    "\n",
    "    test_mean = _data_test.mean(axis=(0, 1))\n",
    "    test_std = _data_test.std(axis=(0, 1))\n",
    "    \n",
    "#     train_mean = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n",
    "#     train_std = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)\n",
    "    \n",
    "#     test_mean = (0.5088964127604166, 0.48739301317401956, 0.44194221124387256)\n",
    "#     test_mean = (0.2682515741720801, 0.2573637364478126, 0.2770957707973042)\n",
    "\n",
    "    print(f'Hard code CIFAR100 train/test mean/std for next time')\n",
    "\n",
    "print('train mean/std:', train_mean, train_std)\n",
    "print('test mean/std:', test_mean, test_std)\n",
    "\n",
    "# Normalize mean std to 0..1 from 0..255\n",
    "train_mean /= 255\n",
    "train_std /= 255\n",
    "test_mean /= 255\n",
    "test_std /= 255\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    # transforms.RandomCrop(32, padding=4),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(train_mean, train_std),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(test_mean, test_std),\n",
    "])\n",
    "\n",
    "# %% Choose model params from dataset\n",
    "\n",
    "if dataset == 'cifar10':\n",
    "    dataloader = datasets.CIFAR10\n",
    "    data_loader_root = os.path.join(DATA_ROOT, 'cifar10')\n",
    "    num_classes = 10\n",
    "    title = 'cifar-10'\n",
    "else:\n",
    "    dataloader = datasets.CIFAR100\n",
    "    data_loader_root = os.path.join(DATA_ROOT, 'cifar100')\n",
    "    num_classes = 100\n",
    "    title = 'cifar-100'\n",
    "\n",
    "# %% Models, criterions, optimizers\n",
    "\n",
    "print(\"==> creating model \")\n",
    "# model = AlexNet(num_classes)\n",
    "#model=resnet.ResNet50()\n",
    "#model=resnext.CifarResNeXt(cardinality=32,depth=4)\n",
    "model=resnext50()\n",
    "# model=DenseNet(growthRate=19)\n",
    "model = model.cuda()\n",
    "\n",
    "# inference_model = torch.nn.DataParallel(inferenece_model).cuda()\n",
    "cudnn.benchmark = True\n",
    "print('\\tTotal params: %.2fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "criterion_attack = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "inference_model = InferenceAttack_HZ(num_classes).cuda()\n",
    "\n",
    "private_train_criterion = nn.MSELoss()\n",
    "\n",
    "optimizer_mem = optim.Adam(inference_model.parameters(), lr=0.00001)\n",
    "\n",
    "# %% Load Dataset from file\n",
    "print(\"==> Loading selected datasets\")\n",
    "batch_privacy = 100\n",
    "trainset = dataloader(root=data_loader_root, train=True, download=True, transform=transform_train)\n",
    "trainloader = data.DataLoader(trainset, batch_size=batch_privacy, shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "# TODO check loader for trainloader_private\n",
    "trainset_private = dataloader(root=data_loader_root, train=True, download=True, transform=transform_test)\n",
    "trainloader_private = data.DataLoader(trainset, batch_size=batch_privacy, shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "testset = dataloader(root=data_loader_root, train=False, download=False, transform=transform_test)\n",
    "testloader = data.DataLoader(testset, batch_size=batch_privacy, shuffle=True, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52ace81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 400] LR: 0.050000\n",
      "(   1) Data: 0.02s | Batch: 10.21s || Loss: 2.352 | Top1: 7.00% | Top5: 54.00%\n",
      "( 101) Data: 0.01s | Batch: 0.39s || Loss: 5.520 | Top1: 11.64% | Top5: 53.50%\n",
      "( 201) Data: 0.01s | Batch: 0.34s || Loss: 3.855 | Top1: 16.26% | Top5: 63.50%\n",
      "( 301) Data: 0.01s | Batch: 0.33s || Loss: 3.205 | Top1: 20.28% | Top5: 69.95%\n",
      "( 401) Data: 0.01s | Batch: 0.32s || Loss: 2.839 | Top1: 24.14% | Top5: 74.16%\n",
      "(   1) Data: 0.02s | Batch: 0.19s || Loss: 1.489 | Top1: 44.00% | Top5: 95.00%\n",
      "Test Acc: 42.59%\n",
      "\n",
      "Epoch: [2 | 400] LR: 0.050000\n",
      "(   1) Data: 0.01s | Batch: 0.17s || Loss: 1.540 | Top1: 44.00% | Top5: 96.00%\n",
      "( 101) Data: 0.01s | Batch: 0.27s || Loss: 1.542 | Top1: 43.16% | Top5: 90.95%\n",
      "( 201) Data: 0.01s | Batch: 0.27s || Loss: 1.496 | Top1: 44.88% | Top5: 91.54%\n",
      "( 301) Data: 0.01s | Batch: 0.27s || Loss: 1.463 | Top1: 46.19% | Top5: 92.12%\n",
      "( 401) Data: 0.01s | Batch: 0.27s || Loss: 1.433 | Top1: 47.44% | Top5: 92.37%\n",
      "(   1) Data: 0.01s | Batch: 0.18s || Loss: 1.270 | Top1: 60.00% | Top5: 95.00%\n",
      "Test Acc: 56.22%\n",
      "\n",
      "Epoch: [3 | 400] LR: 0.050000\n",
      "(   1) Data: 0.02s | Batch: 0.18s || Loss: 1.188 | Top1: 55.00% | Top5: 99.00%\n",
      "( 101) Data: 0.01s | Batch: 0.28s || Loss: 1.177 | Top1: 57.37% | Top5: 95.50%\n",
      "( 201) Data: 0.01s | Batch: 0.27s || Loss: 1.163 | Top1: 57.85% | Top5: 95.52%\n",
      "( 301) Data: 0.01s | Batch: 0.27s || Loss: 1.135 | Top1: 58.99% | Top5: 95.75%\n",
      "( 401) Data: 0.01s | Batch: 0.27s || Loss: 1.122 | Top1: 59.63% | Top5: 95.85%\n",
      "(   1) Data: 0.00s | Batch: 0.19s || Loss: 1.041 | Top1: 64.00% | Top5: 99.00%\n",
      "Test Acc: 63.24%\n",
      "\n",
      "Epoch: [4 | 400] LR: 0.050000\n",
      "(   1) Data: 0.01s | Batch: 0.17s || Loss: 0.820 | Top1: 74.00% | Top5: 98.00%\n",
      "( 101) Data: 0.01s | Batch: 0.27s || Loss: 0.923 | Top1: 67.60% | Top5: 97.36%\n",
      "( 201) Data: 0.01s | Batch: 0.27s || Loss: 0.911 | Top1: 67.85% | Top5: 97.43%\n",
      "( 301) Data: 0.01s | Batch: 0.27s || Loss: 0.893 | Top1: 68.41% | Top5: 97.59%\n",
      "( 401) Data: 0.01s | Batch: 0.27s || Loss: 0.877 | Top1: 68.95% | Top5: 97.64%\n",
      "(   1) Data: 0.01s | Batch: 0.17s || Loss: 0.894 | Top1: 67.00% | Top5: 99.00%\n",
      "Test Acc: 72.24%\n",
      "\n",
      "Epoch: [5 | 400] LR: 0.050000\n",
      "(   0) Data: 0.03s | Batch: 3.82s || Loss: 0.250 | Top1: 53.00%\n",
      "(   1) Data: 0.02s | Batch: 0.39s || Loss: 0.876 | Top1: 78.00% | Top5: 100.00%\n",
      "Privacy Res: 51.00% | 76.00%\n",
      "(  10) Data: 0.03s | Batch: 0.37s || Loss: 0.250 | Top1: 50.00%\n",
      "(  30) Data: 0.03s | Batch: 0.35s || Loss: 0.250 | Top1: 50.00%\n",
      "Privacy Res: 50.00% | 77.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 50.00%\n",
      "(  60) Data: 0.02s | Batch: 0.31s || Loss: 0.250 | Top1: 49.50%\n",
      "Privacy Res: 49.17% | 73.50%\n",
      "(  70) Data: 0.03s | Batch: 0.37s || Loss: 0.250 | Top1: 50.50%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 51.00%\n",
      "Privacy Res: 50.83% | 76.50%\n",
      "Privacy Res: 0.00% | 68.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 49.50%\n",
      "( 101) Data: 0.02s | Batch: 0.43s || Loss: 0.897 | Top1: 78.00% | Top5: 99.00%\n",
      "Privacy Res: 49.67% | 74.50%\n",
      "(  10) Data: 0.02s | Batch: 0.39s || Loss: 0.250 | Top1: 50.50%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 52.00%\n",
      "Privacy Res: 51.33% | 78.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 49.25%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 48.50%\n",
      "Privacy Res: 49.83% | 75.50%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 50.25%\n",
      "(  90) Data: 0.01s | Batch: 0.30s || Loss: 0.250 | Top1: 50.50%\n",
      "Privacy Res: 50.83% | 77.50%\n",
      "Privacy Res: 0.00% | 73.50%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 47.50%\n",
      "( 201) Data: 0.02s | Batch: 0.39s || Loss: 1.072 | Top1: 73.00% | Top5: 97.00%\n",
      "Privacy Res: 50.67% | 72.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 50.75%\n",
      "(  30) Data: 0.02s | Batch: 0.31s || Loss: 0.250 | Top1: 42.50%\n",
      "Privacy Res: 46.50% | 73.00%\n",
      "(  40) Data: 0.03s | Batch: 0.37s || Loss: 0.250 | Top1: 50.25%\n",
      "(  60) Data: 0.02s | Batch: 0.31s || Loss: 0.250 | Top1: 49.00%\n",
      "Privacy Res: 50.17% | 77.00%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 49.25%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 51.00%\n",
      "Privacy Res: 49.33% | 79.00%\n",
      "Privacy Res: 0.00% | 76.50%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 53.00%\n",
      "( 301) Data: 0.02s | Batch: 0.41s || Loss: 1.018 | Top1: 73.00% | Top5: 98.00%\n",
      "Privacy Res: 52.67% | 74.50%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 50.75%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 53.00%\n",
      "Privacy Res: 51.17% | 74.50%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 49.25%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 46.50%\n",
      "Privacy Res: 50.33% | 81.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 52.50%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 52.00%\n",
      "Privacy Res: 50.17% | 71.50%\n",
      "Privacy Res: 0.00% | 77.00%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 45.00%\n",
      "( 401) Data: 0.02s | Batch: 0.41s || Loss: 0.728 | Top1: 84.00% | Top5: 99.00%\n",
      "Privacy Res: 47.50% | 78.50%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 46.75%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 50.00%\n",
      "Privacy Res: 50.50% | 74.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 50.00%\n",
      "(  60) Data: 0.04s | Batch: 0.30s || Loss: 0.250 | Top1: 49.50%\n",
      "Privacy Res: 49.83% | 78.50%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 49.75%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 48.00%\n",
      "Privacy Res: 51.33% | 79.50%\n",
      "Privacy Res: 0.00% | 78.00%\n",
      "(   1) Data: 0.02s | Batch: 0.19s || Loss: 0.873 | Top1: 73.00% | Top5: 96.00%\n",
      "Test Acc: 75.51%\n",
      "\n",
      "Epoch: [6 | 400] LR: 0.050000\n",
      "(   0) Data: 0.02s | Batch: 0.23s || Loss: 0.250 | Top1: 48.00%\n",
      "(   1) Data: 0.02s | Batch: 0.39s || Loss: 0.780 | Top1: 82.00% | Top5: 100.00%\n",
      "Privacy Res: 50.17% | 79.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 52.25%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 48.50%\n",
      "Privacy Res: 48.33% | 80.50%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 49.00%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 47.50%\n",
      "Privacy Res: 50.67% | 83.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 53.50%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 49.00%\n",
      "Privacy Res: 52.67% | 84.50%\n",
      "Privacy Res: 0.00% | 86.50%\n",
      "(   0) Data: 0.04s | Batch: 0.31s || Loss: 0.250 | Top1: 55.00%\n",
      "( 101) Data: 0.00s | Batch: 0.41s || Loss: 0.811 | Top1: 78.00% | Top5: 99.00%\n",
      "Privacy Res: 51.50% | 82.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 49.75%\n",
      "(  30) Data: 0.04s | Batch: 0.31s || Loss: 0.250 | Top1: 49.50%\n",
      "Privacy Res: 52.33% | 79.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 51.00%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 49.50%\n",
      "Privacy Res: 49.33% | 81.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 52.50%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 51.00%\n",
      "Privacy Res: 51.50% | 80.50%\n",
      "Privacy Res: 0.00% | 80.50%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 51.00%\n",
      "( 201) Data: 0.02s | Batch: 0.41s || Loss: 1.102 | Top1: 74.00% | Top5: 97.00%\n",
      "Privacy Res: 51.00% | 77.50%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 49.50%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 54.50%\n",
      "Privacy Res: 50.67% | 83.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 52.25%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 49.50%\n",
      "Privacy Res: 48.83% | 79.00%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 48.50%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 50.50%\n",
      "Privacy Res: 51.33% | 85.00%\n",
      "Privacy Res: 0.00% | 79.50%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 51.50%\n",
      "( 301) Data: 0.02s | Batch: 0.41s || Loss: 0.729 | Top1: 79.00% | Top5: 99.00%\n",
      "Privacy Res: 50.50% | 79.50%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 53.75%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 49.00%\n",
      "Privacy Res: 49.17% | 82.50%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 51.75%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 53.00%\n",
      "Privacy Res: 52.17% | 84.50%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 51.75%\n",
      "(  90) Data: 0.03s | Batch: 0.32s || Loss: 0.250 | Top1: 54.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Privacy Res: 50.83% | 82.50%\n",
      "Privacy Res: 0.00% | 80.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 56.50%\n",
      "( 401) Data: 0.00s | Batch: 0.39s || Loss: 0.712 | Top1: 87.00% | Top5: 97.00%\n",
      "Privacy Res: 52.00% | 85.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 48.50%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 44.50%\n",
      "Privacy Res: 50.50% | 83.50%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 50.25%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 52.50%\n",
      "Privacy Res: 53.83% | 83.50%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 48.50%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 51.50%\n",
      "Privacy Res: 51.83% | 82.00%\n",
      "Privacy Res: 0.00% | 79.50%\n",
      "(   1) Data: 0.02s | Batch: 0.19s || Loss: 0.674 | Top1: 76.00% | Top5: 100.00%\n",
      "Test Acc: 76.61%\n",
      "\n",
      "Epoch: [7 | 400] LR: 0.050000\n",
      "(   0) Data: 0.03s | Batch: 0.25s || Loss: 0.250 | Top1: 47.50%\n",
      "(   1) Data: 0.02s | Batch: 0.41s || Loss: 0.691 | Top1: 83.00% | Top5: 100.00%\n",
      "Privacy Res: 49.67% | 84.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 52.75%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 52.50%\n",
      "Privacy Res: 53.00% | 81.00%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 53.25%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 55.00%\n",
      "Privacy Res: 51.50% | 85.50%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 52.00%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 42.50%\n",
      "Privacy Res: 44.50% | 89.00%\n",
      "Privacy Res: 0.00% | 83.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 52.50%\n",
      "( 101) Data: 0.00s | Batch: 0.39s || Loss: 0.670 | Top1: 88.00% | Top5: 100.00%\n",
      "Privacy Res: 50.83% | 85.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 52.75%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 56.00%\n",
      "Privacy Res: 53.50% | 85.50%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 48.75%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 51.00%\n",
      "Privacy Res: 49.83% | 87.50%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 52.00%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 47.50%\n",
      "Privacy Res: 49.17% | 84.50%\n",
      "Privacy Res: 0.00% | 84.50%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 42.00%\n",
      "( 201) Data: 0.02s | Batch: 0.41s || Loss: 0.685 | Top1: 84.00% | Top5: 100.00%\n",
      "Privacy Res: 47.17% | 83.50%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 58.00%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 49.50%\n",
      "Privacy Res: 50.00% | 87.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 48.50%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 48.50%\n",
      "Privacy Res: 48.17% | 82.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 55.00%\n",
      "(  90) Data: 0.04s | Batch: 0.30s || Loss: 0.250 | Top1: 48.50%\n",
      "Privacy Res: 53.00% | 78.00%\n",
      "Privacy Res: 0.00% | 87.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 51.50%\n",
      "( 301) Data: 0.02s | Batch: 0.41s || Loss: 0.657 | Top1: 88.00% | Top5: 99.00%\n",
      "Privacy Res: 50.50% | 85.50%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 49.00%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 53.50%\n",
      "Privacy Res: 51.17% | 88.50%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 52.00%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 52.50%\n",
      "Privacy Res: 51.50% | 81.50%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 49.75%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 49.00%\n",
      "Privacy Res: 50.67% | 79.50%\n",
      "Privacy Res: 0.00% | 82.50%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 44.00%\n",
      "( 401) Data: 0.02s | Batch: 0.41s || Loss: 0.790 | Top1: 81.00% | Top5: 98.00%\n",
      "Privacy Res: 48.17% | 80.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 52.25%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 55.50%\n",
      "Privacy Res: 53.00% | 83.50%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 49.50%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 53.50%\n",
      "Privacy Res: 53.33% | 86.50%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 46.25%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 49.50%\n",
      "Privacy Res: 51.33% | 82.00%\n",
      "Privacy Res: 0.00% | 84.50%\n",
      "(   1) Data: 0.00s | Batch: 0.17s || Loss: 0.539 | Top1: 80.00% | Top5: 99.00%\n",
      "Test Acc: 80.69%\n",
      "\n",
      "Epoch: [8 | 400] LR: 0.050000\n",
      "(   0) Data: 0.03s | Batch: 0.24s || Loss: 0.250 | Top1: 55.50%\n",
      "(   1) Data: 0.03s | Batch: 0.41s || Loss: 0.584 | Top1: 90.00% | Top5: 100.00%\n",
      "Privacy Res: 51.33% | 87.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 50.75%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 55.50%\n",
      "Privacy Res: 52.17% | 87.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 51.00%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 52.50%\n",
      "Privacy Res: 52.00% | 85.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 50.25%\n",
      "(  90) Data: 0.03s | Batch: 0.32s || Loss: 0.250 | Top1: 54.00%\n",
      "Privacy Res: 51.50% | 90.50%\n",
      "Privacy Res: 0.00% | 89.50%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 51.50%\n",
      "( 101) Data: 0.02s | Batch: 0.41s || Loss: 0.688 | Top1: 88.00% | Top5: 98.00%\n",
      "Privacy Res: 53.17% | 88.50%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 51.75%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 49.00%\n",
      "Privacy Res: 51.00% | 88.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 49.25%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 47.50%\n",
      "Privacy Res: 50.50% | 88.00%\n",
      "(  70) Data: 0.03s | Batch: 0.37s || Loss: 0.250 | Top1: 50.00%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 51.50%\n",
      "Privacy Res: 54.83% | 87.50%\n",
      "Privacy Res: 0.00% | 87.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 45.00%\n",
      "( 201) Data: 0.00s | Batch: 0.39s || Loss: 0.534 | Top1: 89.00% | Top5: 100.00%\n",
      "Privacy Res: 52.67% | 87.50%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 53.00%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 50.00%\n",
      "Privacy Res: 53.33% | 84.50%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 53.00%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 53.50%\n",
      "Privacy Res: 53.17% | 83.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 56.00%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 49.50%\n",
      "Privacy Res: 51.50% | 85.50%\n",
      "Privacy Res: 0.00% | 87.50%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 53.50%\n",
      "( 301) Data: 0.00s | Batch: 0.39s || Loss: 0.636 | Top1: 85.00% | Top5: 99.00%\n",
      "Privacy Res: 52.67% | 82.50%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 48.50%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 51.50%\n",
      "Privacy Res: 50.83% | 83.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 49.00%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 52.00%\n",
      "Privacy Res: 52.00% | 82.00%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 50.00%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 46.00%\n",
      "Privacy Res: 50.17% | 85.00%\n",
      "Privacy Res: 0.00% | 84.50%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 55.50%\n",
      "( 401) Data: 0.02s | Batch: 0.41s || Loss: 0.620 | Top1: 89.00% | Top5: 100.00%\n",
      "Privacy Res: 52.00% | 88.00%\n",
      "(  10) Data: 0.05s | Batch: 0.38s || Loss: 0.250 | Top1: 51.75%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 51.50%\n",
      "Privacy Res: 49.50% | 85.50%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 52.25%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 50.50%\n",
      "Privacy Res: 52.17% | 87.50%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 51.50%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 49.50%\n",
      "Privacy Res: 47.67% | 86.50%\n",
      "Privacy Res: 0.00% | 86.50%\n",
      "(   1) Data: 0.00s | Batch: 0.17s || Loss: 0.422 | Top1: 84.00% | Top5: 100.00%\n",
      "Test Acc: 78.59%\n",
      "\n",
      "Epoch: [9 | 400] LR: 0.050000\n",
      "(   0) Data: 0.04s | Batch: 0.24s || Loss: 0.250 | Top1: 52.50%\n",
      "(   1) Data: 0.02s | Batch: 0.41s || Loss: 0.505 | Top1: 90.00% | Top5: 100.00%\n",
      "Privacy Res: 52.00% | 89.50%\n",
      "(  10) Data: 0.03s | Batch: 0.37s || Loss: 0.250 | Top1: 51.50%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 51.50%\n",
      "Privacy Res: 50.00% | 90.50%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 49.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 50.00%\n",
      "Privacy Res: 54.67% | 89.00%\n",
      "(  70) Data: 0.03s | Batch: 0.37s || Loss: 0.250 | Top1: 52.50%\n",
      "(  90) Data: 0.04s | Batch: 0.31s || Loss: 0.250 | Top1: 47.00%\n",
      "Privacy Res: 50.00% | 85.00%\n",
      "Privacy Res: 0.00% | 92.00%\n",
      "(   0) Data: 0.03s | Batch: 0.32s || Loss: 0.250 | Top1: 55.50%\n",
      "( 101) Data: 0.00s | Batch: 0.39s || Loss: 0.658 | Top1: 87.00% | Top5: 98.00%\n",
      "Privacy Res: 50.67% | 85.50%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 47.25%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 56.00%\n",
      "Privacy Res: 54.50% | 88.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 52.75%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 50.00%\n",
      "Privacy Res: 48.83% | 87.50%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 52.00%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 48.50%\n",
      "Privacy Res: 51.33% | 86.00%\n",
      "Privacy Res: 0.00% | 85.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 54.00%\n",
      "( 201) Data: 0.02s | Batch: 0.41s || Loss: 0.602 | Top1: 87.00% | Top5: 99.00%\n",
      "Privacy Res: 51.83% | 87.50%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 51.00%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 55.50%\n",
      "Privacy Res: 51.83% | 90.50%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 48.00%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 50.50%\n",
      "Privacy Res: 51.33% | 89.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 49.50%\n",
      "(  90) Data: 0.05s | Batch: 0.32s || Loss: 0.250 | Top1: 51.00%\n",
      "Privacy Res: 51.00% | 87.00%\n",
      "Privacy Res: 0.00% | 89.50%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 58.50%\n",
      "( 301) Data: 0.00s | Batch: 0.39s || Loss: 0.728 | Top1: 84.00% | Top5: 99.00%\n",
      "Privacy Res: 54.17% | 85.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 49.75%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 49.50%\n",
      "Privacy Res: 48.50% | 88.00%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 55.25%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 51.00%\n",
      "Privacy Res: 53.50% | 92.00%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 50.50%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 51.00%\n",
      "Privacy Res: 49.50% | 88.00%\n",
      "Privacy Res: 0.00% | 89.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 54.00%\n",
      "( 401) Data: 0.01s | Batch: 0.41s || Loss: 0.884 | Top1: 80.00% | Top5: 100.00%\n",
      "Privacy Res: 53.50% | 84.50%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 50.25%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 42.50%\n",
      "Privacy Res: 50.00% | 90.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 48.75%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 48.00%\n",
      "Privacy Res: 49.83% | 80.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 52.75%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 54.00%\n",
      "Privacy Res: 52.17% | 87.50%\n",
      "Privacy Res: 0.00% | 85.00%\n",
      "(   1) Data: 0.02s | Batch: 0.18s || Loss: 0.531 | Top1: 82.00% | Top5: 99.00%\n",
      "Test Acc: 79.30%\n",
      "\n",
      "Epoch: [10 | 400] LR: 0.050000\n",
      "(   0) Data: 0.03s | Batch: 0.23s || Loss: 0.250 | Top1: 48.50%\n",
      "(   1) Data: 0.02s | Batch: 0.41s || Loss: 0.597 | Top1: 87.00% | Top5: 99.00%\n",
      "Privacy Res: 52.33% | 88.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 50.50%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 50.00%\n",
      "Privacy Res: 52.50% | 93.50%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 52.00%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 48.00%\n",
      "Privacy Res: 49.50% | 93.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 52.00%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 51.00%\n",
      "Privacy Res: 53.00% | 90.50%\n",
      "Privacy Res: 0.00% | 91.00%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 50.00%\n",
      "( 101) Data: 0.02s | Batch: 0.41s || Loss: 0.507 | Top1: 90.00% | Top5: 99.00%\n",
      "Privacy Res: 49.17% | 90.50%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 47.25%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 51.00%\n",
      "Privacy Res: 51.17% | 91.50%\n",
      "(  40) Data: 0.03s | Batch: 0.37s || Loss: 0.250 | Top1: 53.00%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 50.50%\n",
      "Privacy Res: 51.33% | 92.50%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 57.75%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 52.50%\n",
      "Privacy Res: 49.83% | 89.00%\n",
      "Privacy Res: 0.00% | 93.50%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 47.50%\n",
      "( 201) Data: 0.02s | Batch: 0.41s || Loss: 0.658 | Top1: 85.00% | Top5: 99.00%\n",
      "Privacy Res: 50.83% | 86.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 52.50%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 59.00%\n",
      "Privacy Res: 54.17% | 91.00%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 52.50%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 46.50%\n",
      "Privacy Res: 46.83% | 88.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 51.00%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 41.00%\n",
      "Privacy Res: 48.83% | 88.00%\n",
      "Privacy Res: 0.00% | 86.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 55.00%\n",
      "( 301) Data: 0.02s | Batch: 0.41s || Loss: 0.664 | Top1: 87.00% | Top5: 100.00%\n",
      "Privacy Res: 52.67% | 87.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 54.75%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 51.50%\n",
      "Privacy Res: 55.83% | 87.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 51.50%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 47.00%\n",
      "Privacy Res: 48.17% | 85.50%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 49.00%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 52.50%\n",
      "Privacy Res: 50.17% | 86.50%\n",
      "Privacy Res: 0.00% | 89.50%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 50.50%\n",
      "( 401) Data: 0.02s | Batch: 0.41s || Loss: 0.629 | Top1: 85.00% | Top5: 100.00%\n",
      "Privacy Res: 51.50% | 88.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 47.75%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 50.00%\n",
      "Privacy Res: 52.83% | 86.50%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 48.75%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 53.00%\n",
      "Privacy Res: 55.33% | 88.00%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 51.00%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 46.00%\n",
      "Privacy Res: 50.67% | 85.00%\n",
      "Privacy Res: 0.00% | 91.00%\n",
      "(   1) Data: 0.02s | Batch: 0.17s || Loss: 0.569 | Top1: 84.00% | Top5: 98.00%\n",
      "Test Acc: 80.31%\n",
      "\n",
      "Epoch: [11 | 400] LR: 0.050000\n",
      "(   0) Data: 0.02s | Batch: 0.23s || Loss: 0.250 | Top1: 58.50%\n",
      "(   1) Data: 0.02s | Batch: 0.41s || Loss: 0.393 | Top1: 96.00% | Top5: 100.00%\n",
      "Privacy Res: 51.83% | 94.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 55.50%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 49.50%\n",
      "Privacy Res: 50.00% | 91.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 54.50%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 55.50%\n",
      "Privacy Res: 55.83% | 91.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 44.25%\n",
      "(  90) Data: 0.02s | Batch: 0.31s || Loss: 0.250 | Top1: 54.00%\n",
      "Privacy Res: 50.17% | 91.50%\n",
      "Privacy Res: 0.00% | 87.50%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 54.00%\n",
      "( 101) Data: 0.02s | Batch: 0.41s || Loss: 0.437 | Top1: 94.00% | Top5: 100.00%\n",
      "Privacy Res: 53.00% | 92.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 49.25%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 50.50%\n",
      "Privacy Res: 52.00% | 92.50%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 51.75%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 49.50%\n",
      "Privacy Res: 51.83% | 90.00%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 50.50%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 54.00%\n",
      "Privacy Res: 52.33% | 91.00%\n",
      "Privacy Res: 0.00% | 87.50%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 54.50%\n",
      "( 201) Data: 0.00s | Batch: 0.40s || Loss: 0.461 | Top1: 91.00% | Top5: 100.00%\n",
      "Privacy Res: 52.67% | 91.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 51.25%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 50.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Privacy Res: 49.50% | 90.50%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 52.25%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 52.00%\n",
      "Privacy Res: 50.33% | 86.00%\n",
      "(  70) Data: 0.01s | Batch: 0.37s || Loss: 0.250 | Top1: 55.00%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 53.50%\n",
      "Privacy Res: 48.33% | 92.00%\n",
      "Privacy Res: 0.00% | 92.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 50.00%\n",
      "( 301) Data: 0.01s | Batch: 0.41s || Loss: 0.605 | Top1: 87.00% | Top5: 100.00%\n",
      "Privacy Res: 53.67% | 88.50%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 54.00%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 49.00%\n",
      "Privacy Res: 51.00% | 90.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 54.50%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 51.50%\n",
      "Privacy Res: 53.33% | 88.50%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 53.75%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 49.00%\n",
      "Privacy Res: 51.67% | 88.00%\n",
      "Privacy Res: 0.00% | 87.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 49.50%\n",
      "( 401) Data: 0.02s | Batch: 0.41s || Loss: 0.542 | Top1: 92.00% | Top5: 99.00%\n",
      "Privacy Res: 51.33% | 91.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 54.50%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 51.50%\n",
      "Privacy Res: 50.50% | 89.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 50.50%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 51.00%\n",
      "Privacy Res: 54.83% | 85.50%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 53.00%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 55.50%\n",
      "Privacy Res: 53.67% | 89.50%\n",
      "Privacy Res: 0.00% | 88.50%\n",
      "(   1) Data: 0.02s | Batch: 0.17s || Loss: 0.379 | Top1: 90.00% | Top5: 100.00%\n",
      "Test Acc: 80.76%\n",
      "\n",
      "Epoch: [12 | 400] LR: 0.050000\n",
      "(   0) Data: 0.03s | Batch: 0.23s || Loss: 0.250 | Top1: 52.00%\n",
      "(   1) Data: 0.02s | Batch: 0.41s || Loss: 0.463 | Top1: 92.00% | Top5: 100.00%\n",
      "Privacy Res: 50.83% | 94.50%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 54.25%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 52.00%\n",
      "Privacy Res: 52.50% | 95.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 50.75%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.249 | Top1: 56.50%\n",
      "Privacy Res: 53.83% | 91.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 51.00%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 50.50%\n",
      "Privacy Res: 51.67% | 94.00%\n",
      "Privacy Res: 0.00% | 92.50%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.251 | Top1: 43.50%\n",
      "( 101) Data: 0.02s | Batch: 0.41s || Loss: 0.375 | Top1: 94.00% | Top5: 100.00%\n",
      "Privacy Res: 51.83% | 94.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 49.25%\n",
      "(  30) Data: 0.02s | Batch: 0.31s || Loss: 0.249 | Top1: 52.00%\n",
      "Privacy Res: 52.17% | 89.50%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.249 | Top1: 55.75%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.249 | Top1: 55.00%\n",
      "Privacy Res: 54.00% | 91.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.249 | Top1: 55.25%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 52.00%\n",
      "Privacy Res: 52.67% | 94.50%\n",
      "Privacy Res: 0.00% | 93.50%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 53.50%\n",
      "( 201) Data: 0.02s | Batch: 0.41s || Loss: 0.425 | Top1: 93.00% | Top5: 100.00%\n",
      "Privacy Res: 55.00% | 92.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.249 | Top1: 55.75%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 52.00%\n",
      "Privacy Res: 53.00% | 95.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 52.25%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.249 | Top1: 54.50%\n",
      "Privacy Res: 55.83% | 93.00%\n",
      "(  70) Data: 0.03s | Batch: 0.37s || Loss: 0.250 | Top1: 54.50%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.249 | Top1: 54.50%\n",
      "Privacy Res: 52.50% | 91.00%\n",
      "Privacy Res: 0.00% | 90.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 46.00%\n",
      "( 301) Data: 0.02s | Batch: 0.41s || Loss: 0.510 | Top1: 92.00% | Top5: 100.00%\n",
      "Privacy Res: 49.50% | 89.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 48.00%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 51.00%\n",
      "Privacy Res: 47.33% | 92.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 49.25%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.249 | Top1: 52.50%\n",
      "Privacy Res: 51.83% | 93.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.249 | Top1: 55.50%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 52.00%\n",
      "Privacy Res: 50.67% | 94.00%\n",
      "Privacy Res: 0.00% | 93.00%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.248 | Top1: 55.00%\n",
      "( 401) Data: 0.00s | Batch: 0.40s || Loss: 0.434 | Top1: 95.00% | Top5: 100.00%\n",
      "Privacy Res: 54.33% | 93.50%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.249 | Top1: 51.50%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.249 | Top1: 52.50%\n",
      "Privacy Res: 53.17% | 88.50%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 48.75%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 51.00%\n",
      "Privacy Res: 51.83% | 88.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.251 | Top1: 49.75%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 48.00%\n",
      "Privacy Res: 50.83% | 86.00%\n",
      "Privacy Res: 0.00% | 94.00%\n",
      "(   1) Data: 0.02s | Batch: 0.19s || Loss: 0.655 | Top1: 80.00% | Top5: 100.00%\n",
      "Test Acc: 80.41%\n",
      "\n",
      "Epoch: [13 | 400] LR: 0.050000\n",
      "(   0) Data: 0.03s | Batch: 0.24s || Loss: 0.248 | Top1: 58.50%\n",
      "(   1) Data: 0.02s | Batch: 0.41s || Loss: 0.412 | Top1: 96.00% | Top5: 100.00%\n",
      "Privacy Res: 53.50% | 96.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.249 | Top1: 55.50%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 52.00%\n",
      "Privacy Res: 51.50% | 93.50%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.249 | Top1: 55.25%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.251 | Top1: 47.50%\n",
      "Privacy Res: 50.83% | 95.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.248 | Top1: 56.25%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 50.00%\n",
      "Privacy Res: 52.83% | 91.50%\n",
      "Privacy Res: 0.00% | 95.00%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 50.00%\n",
      "( 101) Data: 0.00s | Batch: 0.39s || Loss: 0.385 | Top1: 95.00% | Top5: 100.00%\n",
      "Privacy Res: 50.33% | 94.00%\n",
      "(  10) Data: 0.03s | Batch: 0.37s || Loss: 0.248 | Top1: 57.25%\n",
      "(  30) Data: 0.04s | Batch: 0.31s || Loss: 0.251 | Top1: 49.50%\n",
      "Privacy Res: 54.50% | 93.50%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.248 | Top1: 54.50%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.249 | Top1: 54.00%\n",
      "Privacy Res: 55.50% | 92.50%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.249 | Top1: 52.75%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.249 | Top1: 55.50%\n",
      "Privacy Res: 54.67% | 91.50%\n",
      "Privacy Res: 0.00% | 93.00%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.248 | Top1: 55.00%\n",
      "( 201) Data: 0.02s | Batch: 0.41s || Loss: 0.423 | Top1: 96.00% | Top5: 100.00%\n",
      "Privacy Res: 53.50% | 91.50%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.249 | Top1: 52.75%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.248 | Top1: 59.00%\n",
      "Privacy Res: 55.50% | 88.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.249 | Top1: 52.75%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.248 | Top1: 54.50%\n",
      "Privacy Res: 53.17% | 95.50%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.249 | Top1: 52.25%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.249 | Top1: 52.00%\n",
      "Privacy Res: 51.67% | 93.50%\n",
      "Privacy Res: 0.00% | 93.50%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.249 | Top1: 55.50%\n",
      "( 301) Data: 0.02s | Batch: 0.41s || Loss: 0.418 | Top1: 94.00% | Top5: 100.00%\n",
      "Privacy Res: 53.67% | 91.50%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.249 | Top1: 55.00%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 48.50%\n",
      "Privacy Res: 52.33% | 93.50%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.248 | Top1: 56.75%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.248 | Top1: 54.50%\n",
      "Privacy Res: 54.33% | 93.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.248 | Top1: 54.75%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.246 | Top1: 55.50%\n",
      "Privacy Res: 54.67% | 89.00%\n",
      "Privacy Res: 0.00% | 95.50%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.247 | Top1: 52.00%\n",
      "( 401) Data: 0.02s | Batch: 0.41s || Loss: 0.557 | Top1: 88.00% | Top5: 99.00%\n",
      "Privacy Res: 55.67% | 88.50%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.248 | Top1: 54.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 50.00%\n",
      "Privacy Res: 55.67% | 88.00%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.248 | Top1: 53.75%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.249 | Top1: 51.50%\n",
      "Privacy Res: 50.50% | 90.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.251 | Top1: 49.75%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.249 | Top1: 53.50%\n",
      "Privacy Res: 53.00% | 91.00%\n",
      "Privacy Res: 0.00% | 93.00%\n",
      "(   1) Data: 0.03s | Batch: 0.19s || Loss: 0.522 | Top1: 81.00% | Top5: 100.00%\n",
      "Test Acc: 83.93%\n",
      "\n",
      "Epoch: [14 | 400] LR: 0.050000\n",
      "(   0) Data: 0.03s | Batch: 0.23s || Loss: 0.248 | Top1: 55.00%\n",
      "(   1) Data: 0.02s | Batch: 0.39s || Loss: 0.378 | Top1: 97.00% | Top5: 100.00%\n",
      "Privacy Res: 51.33% | 96.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 51.50%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.251 | Top1: 52.50%\n",
      "Privacy Res: 53.33% | 93.00%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.248 | Top1: 55.50%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.246 | Top1: 58.00%\n",
      "Privacy Res: 54.00% | 96.50%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.249 | Top1: 52.00%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 52.00%\n",
      "Privacy Res: 52.67% | 98.00%\n",
      "Privacy Res: 0.00% | 94.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.252 | Top1: 42.50%\n",
      "( 101) Data: 0.00s | Batch: 0.39s || Loss: 0.442 | Top1: 95.00% | Top5: 100.00%\n",
      "Privacy Res: 48.33% | 94.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.248 | Top1: 54.25%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.248 | Top1: 56.50%\n",
      "Privacy Res: 53.00% | 94.00%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.247 | Top1: 56.75%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.251 | Top1: 52.00%\n",
      "Privacy Res: 55.83% | 95.50%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.249 | Top1: 53.25%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.246 | Top1: 57.00%\n",
      "Privacy Res: 58.00% | 94.50%\n",
      "Privacy Res: 0.00% | 92.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.246 | Top1: 57.00%\n",
      "( 201) Data: 0.02s | Batch: 0.41s || Loss: 0.495 | Top1: 90.00% | Top5: 100.00%\n",
      "Privacy Res: 58.50% | 89.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 52.00%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.248 | Top1: 53.50%\n",
      "Privacy Res: 54.33% | 88.50%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.247 | Top1: 57.00%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.249 | Top1: 51.00%\n",
      "Privacy Res: 55.33% | 90.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.251 | Top1: 48.25%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 49.50%\n",
      "Privacy Res: 52.33% | 94.00%\n",
      "Privacy Res: 0.00% | 92.50%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.249 | Top1: 53.00%\n",
      "( 301) Data: 0.00s | Batch: 0.40s || Loss: 0.501 | Top1: 92.00% | Top5: 100.00%\n",
      "Privacy Res: 55.33% | 93.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.249 | Top1: 54.25%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.247 | Top1: 55.50%\n",
      "Privacy Res: 53.00% | 93.50%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.249 | Top1: 50.50%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.248 | Top1: 52.00%\n",
      "Privacy Res: 54.67% | 97.50%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.249 | Top1: 52.25%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.248 | Top1: 57.50%\n",
      "Privacy Res: 53.67% | 93.00%\n",
      "Privacy Res: 0.00% | 92.00%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 50.50%\n",
      "( 401) Data: 0.02s | Batch: 0.41s || Loss: 0.485 | Top1: 92.00% | Top5: 100.00%\n",
      "Privacy Res: 53.33% | 91.50%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.247 | Top1: 56.50%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 51.00%\n",
      "Privacy Res: 54.33% | 96.50%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 51.00%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.245 | Top1: 55.00%\n",
      "Privacy Res: 52.67% | 90.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.248 | Top1: 53.50%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.247 | Top1: 55.00%\n",
      "Privacy Res: 56.00% | 85.00%\n",
      "Privacy Res: 0.00% | 89.00%\n",
      "(   1) Data: 0.02s | Batch: 0.17s || Loss: 0.435 | Top1: 83.00% | Top5: 99.00%\n",
      "Test Acc: 82.66%\n",
      "\n",
      "Epoch: [15 | 400] LR: 0.050000\n",
      "(   0) Data: 0.02s | Batch: 0.22s || Loss: 0.251 | Top1: 53.00%\n",
      "(   1) Data: 0.02s | Batch: 0.41s || Loss: 0.443 | Top1: 93.00% | Top5: 100.00%\n",
      "Privacy Res: 51.50% | 91.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.248 | Top1: 54.00%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.251 | Top1: 51.50%\n",
      "Privacy Res: 54.00% | 95.00%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.248 | Top1: 54.50%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.251 | Top1: 52.00%\n",
      "Privacy Res: 50.33% | 98.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.246 | Top1: 54.75%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.246 | Top1: 55.50%\n",
      "Privacy Res: 55.00% | 95.50%\n",
      "Privacy Res: 0.00% | 97.50%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.246 | Top1: 55.00%\n",
      "( 101) Data: 0.02s | Batch: 0.40s || Loss: 0.376 | Top1: 98.00% | Top5: 100.00%\n",
      "Privacy Res: 55.83% | 95.50%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.247 | Top1: 53.75%\n",
      "(  30) Data: 0.04s | Batch: 0.31s || Loss: 0.247 | Top1: 53.00%\n",
      "Privacy Res: 55.17% | 92.00%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.248 | Top1: 52.25%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.248 | Top1: 53.00%\n",
      "Privacy Res: 56.00% | 93.50%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.247 | Top1: 53.00%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.251 | Top1: 47.00%\n",
      "Privacy Res: 53.50% | 93.50%\n",
      "Privacy Res: 0.00% | 88.50%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.245 | Top1: 55.50%\n",
      "( 201) Data: 0.02s | Batch: 0.41s || Loss: 0.356 | Top1: 98.00% | Top5: 100.00%\n",
      "Privacy Res: 55.50% | 96.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.250 | Top1: 53.75%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.249 | Top1: 55.00%\n",
      "Privacy Res: 53.83% | 92.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.248 | Top1: 51.25%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.248 | Top1: 54.50%\n",
      "Privacy Res: 54.33% | 93.50%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.247 | Top1: 52.00%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 52.50%\n",
      "Privacy Res: 53.17% | 90.00%\n",
      "Privacy Res: 0.00% | 90.50%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.251 | Top1: 51.00%\n",
      "( 301) Data: 0.02s | Batch: 0.41s || Loss: 0.507 | Top1: 92.00% | Top5: 100.00%\n",
      "Privacy Res: 51.83% | 92.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.248 | Top1: 54.50%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.249 | Top1: 48.50%\n",
      "Privacy Res: 53.83% | 91.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.248 | Top1: 54.00%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.247 | Top1: 55.50%\n",
      "Privacy Res: 52.50% | 85.50%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.248 | Top1: 53.25%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.248 | Top1: 52.00%\n",
      "Privacy Res: 54.50% | 91.00%\n",
      "Privacy Res: 0.00% | 94.50%\n",
      "(   0) Data: 0.09s | Batch: 0.31s || Loss: 0.252 | Top1: 52.00%\n",
      "( 401) Data: 0.02s | Batch: 0.41s || Loss: 0.443 | Top1: 94.00% | Top5: 100.00%\n",
      "Privacy Res: 50.83% | 94.50%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.245 | Top1: 59.00%\n",
      "(  30) Data: 0.02s | Batch: 0.29s || Loss: 0.248 | Top1: 52.00%\n",
      "Privacy Res: 57.00% | 90.00%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.252 | Top1: 48.00%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.247 | Top1: 54.50%\n",
      "Privacy Res: 56.17% | 89.50%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.246 | Top1: 54.75%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.248 | Top1: 52.50%\n",
      "Privacy Res: 53.00% | 91.50%\n",
      "Privacy Res: 0.00% | 92.50%\n",
      "(   1) Data: 0.02s | Batch: 0.17s || Loss: 0.685 | Top1: 78.00% | Top5: 99.00%\n",
      "Test Acc: 82.43%\n",
      "\n",
      "Epoch: [16 | 400] LR: 0.050000\n",
      "(   0) Data: 0.03s | Batch: 0.23s || Loss: 0.251 | Top1: 52.50%\n",
      "(   1) Data: 0.02s | Batch: 0.41s || Loss: 0.414 | Top1: 96.00% | Top5: 100.00%\n",
      "Privacy Res: 55.50% | 94.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.245 | Top1: 58.00%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.248 | Top1: 52.50%\n",
      "Privacy Res: 51.33% | 95.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.248 | Top1: 52.25%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.245 | Top1: 54.00%\n",
      "Privacy Res: 52.17% | 95.50%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.249 | Top1: 53.50%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.244 | Top1: 55.00%\n",
      "Privacy Res: 52.33% | 93.50%\n",
      "Privacy Res: 0.00% | 92.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.243 | Top1: 59.00%\n",
      "( 101) Data: 0.01s | Batch: 0.39s || Loss: 0.580 | Top1: 90.00% | Top5: 100.00%\n",
      "Privacy Res: 57.17% | 93.50%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.246 | Top1: 56.75%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.243 | Top1: 56.50%\n",
      "Privacy Res: 53.67% | 95.50%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 51.75%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.249 | Top1: 55.00%\n",
      "Privacy Res: 54.50% | 94.50%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.244 | Top1: 59.75%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.251 | Top1: 50.50%\n",
      "Privacy Res: 51.33% | 94.50%\n",
      "Privacy Res: 0.00% | 93.50%\n",
      "(   0) Data: 0.03s | Batch: 0.32s || Loss: 0.252 | Top1: 50.50%\n",
      "( 201) Data: 0.02s | Batch: 0.39s || Loss: 0.451 | Top1: 95.00% | Top5: 100.00%\n",
      "Privacy Res: 51.17% | 95.50%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.249 | Top1: 54.50%\n",
      "(  30) Data: 0.02s | Batch: 0.29s || Loss: 0.250 | Top1: 52.00%\n",
      "Privacy Res: 53.67% | 93.50%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.247 | Top1: 56.50%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.246 | Top1: 55.50%\n",
      "Privacy Res: 51.67% | 94.50%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.248 | Top1: 52.25%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.246 | Top1: 54.00%\n",
      "Privacy Res: 53.83% | 93.00%\n",
      "Privacy Res: 0.00% | 92.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.244 | Top1: 55.50%\n",
      "( 301) Data: 0.02s | Batch: 0.41s || Loss: 0.501 | Top1: 93.00% | Top5: 100.00%\n",
      "Privacy Res: 56.50% | 92.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.248 | Top1: 52.75%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 51.00%\n",
      "Privacy Res: 50.33% | 94.00%\n",
      "(  40) Data: 0.01s | Batch: 0.37s || Loss: 0.247 | Top1: 55.75%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.248 | Top1: 51.50%\n",
      "Privacy Res: 51.17% | 92.00%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.248 | Top1: 51.00%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.249 | Top1: 48.50%\n",
      "Privacy Res: 53.67% | 93.00%\n",
      "Privacy Res: 0.00% | 92.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.243 | Top1: 57.50%\n",
      "( 401) Data: 0.02s | Batch: 0.41s || Loss: 0.479 | Top1: 95.00% | Top5: 100.00%\n",
      "Privacy Res: 55.50% | 93.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.249 | Top1: 52.50%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.243 | Top1: 58.00%\n",
      "Privacy Res: 53.67% | 89.50%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.248 | Top1: 53.50%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.246 | Top1: 54.50%\n",
      "Privacy Res: 54.33% | 94.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.248 | Top1: 52.25%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.245 | Top1: 54.00%\n",
      "Privacy Res: 54.33% | 93.00%\n",
      "Privacy Res: 0.00% | 84.50%\n",
      "(   1) Data: 0.02s | Batch: 0.17s || Loss: 0.739 | Top1: 71.00% | Top5: 97.00%\n",
      "Test Acc: 82.23%\n",
      "\n",
      "Epoch: [17 | 400] LR: 0.050000\n",
      "(   0) Data: 0.03s | Batch: 0.23s || Loss: 0.247 | Top1: 55.00%\n",
      "(   1) Data: 0.02s | Batch: 0.41s || Loss: 0.506 | Top1: 91.00% | Top5: 100.00%\n",
      "Privacy Res: 53.83% | 93.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.247 | Top1: 54.25%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.243 | Top1: 57.50%\n",
      "Privacy Res: 55.83% | 95.50%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.246 | Top1: 56.50%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.246 | Top1: 57.00%\n",
      "Privacy Res: 54.67% | 91.50%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.250 | Top1: 52.50%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.251 | Top1: 49.50%\n",
      "Privacy Res: 54.17% | 92.50%\n",
      "Privacy Res: 0.00% | 93.50%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.247 | Top1: 57.00%\n",
      "( 101) Data: 0.00s | Batch: 0.40s || Loss: 0.495 | Top1: 89.00% | Top5: 99.00%\n",
      "Privacy Res: 54.83% | 90.50%\n",
      "(  10) Data: 0.03s | Batch: 0.37s || Loss: 0.250 | Top1: 51.50%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.248 | Top1: 54.50%\n",
      "Privacy Res: 54.50% | 93.50%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.247 | Top1: 53.00%\n",
      "(  60) Data: 0.02s | Batch: 0.31s || Loss: 0.251 | Top1: 54.00%\n",
      "Privacy Res: 52.33% | 93.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.244 | Top1: 55.25%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.251 | Top1: 50.50%\n",
      "Privacy Res: 52.83% | 95.00%\n",
      "Privacy Res: 0.00% | 95.50%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.247 | Top1: 56.50%\n",
      "( 201) Data: 0.02s | Batch: 0.41s || Loss: 0.489 | Top1: 94.00% | Top5: 100.00%\n",
      "Privacy Res: 52.50% | 95.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.249 | Top1: 53.50%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.245 | Top1: 58.50%\n",
      "Privacy Res: 55.67% | 95.50%\n",
      "(  40) Data: 0.03s | Batch: 0.37s || Loss: 0.250 | Top1: 49.25%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.252 | Top1: 53.00%\n",
      "Privacy Res: 53.17% | 93.00%\n",
      "(  70) Data: 0.03s | Batch: 0.37s || Loss: 0.246 | Top1: 56.25%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.248 | Top1: 52.00%\n",
      "Privacy Res: 51.33% | 93.50%\n",
      "Privacy Res: 0.00% | 92.50%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.249 | Top1: 51.50%\n",
      "( 301) Data: 0.02s | Batch: 0.41s || Loss: 0.481 | Top1: 94.00% | Top5: 100.00%\n",
      "Privacy Res: 55.83% | 93.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.243 | Top1: 57.50%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.245 | Top1: 55.50%\n",
      "Privacy Res: 54.33% | 91.50%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 51.25%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.249 | Top1: 54.00%\n",
      "Privacy Res: 55.00% | 90.50%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.249 | Top1: 54.75%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.249 | Top1: 57.00%\n",
      "Privacy Res: 55.50% | 94.50%\n",
      "Privacy Res: 0.00% | 89.50%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.246 | Top1: 57.50%\n",
      "( 401) Data: 0.01s | Batch: 0.43s || Loss: 0.583 | Top1: 89.00% | Top5: 100.00%\n",
      "Privacy Res: 56.17% | 89.50%\n",
      "(  10) Data: 0.03s | Batch: 0.37s || Loss: 0.246 | Top1: 53.50%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.249 | Top1: 47.50%\n",
      "Privacy Res: 50.83% | 92.50%\n",
      "(  40) Data: 0.03s | Batch: 0.37s || Loss: 0.247 | Top1: 52.75%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 53.00%\n",
      "Privacy Res: 54.33% | 93.00%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.245 | Top1: 57.50%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.246 | Top1: 53.50%\n",
      "Privacy Res: 56.00% | 92.00%\n",
      "Privacy Res: 0.00% | 92.50%\n",
      "(   1) Data: 0.00s | Batch: 0.17s || Loss: 0.514 | Top1: 81.00% | Top5: 100.00%\n",
      "Test Acc: 82.69%\n",
      "\n",
      "Epoch: [18 | 400] LR: 0.050000\n",
      "(   0) Data: 0.03s | Batch: 0.23s || Loss: 0.246 | Top1: 56.50%\n",
      "(   1) Data: 0.02s | Batch: 0.41s || Loss: 0.486 | Top1: 95.00% | Top5: 100.00%\n",
      "Privacy Res: 55.67% | 95.50%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.243 | Top1: 59.00%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.248 | Top1: 55.50%\n",
      "Privacy Res: 54.50% | 94.50%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.246 | Top1: 56.50%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.246 | Top1: 52.50%\n",
      "Privacy Res: 55.17% | 96.50%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.248 | Top1: 56.00%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 56.00%\n",
      "Privacy Res: 56.33% | 94.00%\n",
      "Privacy Res: 0.00% | 94.50%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.241 | Top1: 61.00%\n",
      "( 101) Data: 0.02s | Batch: 0.41s || Loss: 0.566 | Top1: 91.00% | Top5: 100.00%\n",
      "Privacy Res: 57.50% | 92.50%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.244 | Top1: 55.75%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.244 | Top1: 56.50%\n",
      "Privacy Res: 56.83% | 94.50%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.246 | Top1: 56.50%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.248 | Top1: 55.00%\n",
      "Privacy Res: 55.50% | 91.00%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.251 | Top1: 51.50%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 49.00%\n",
      "Privacy Res: 50.50% | 95.50%\n",
      "Privacy Res: 0.00% | 91.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 51.50%\n",
      "( 201) Data: 0.02s | Batch: 0.41s || Loss: 0.633 | Top1: 87.00% | Top5: 100.00%\n",
      "Privacy Res: 52.17% | 88.50%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.246 | Top1: 55.50%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.245 | Top1: 57.00%\n",
      "Privacy Res: 54.17% | 93.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.248 | Top1: 55.25%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.245 | Top1: 56.50%\n",
      "Privacy Res: 53.50% | 93.50%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.251 | Top1: 51.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(  90) Data: 0.02s | Batch: 0.31s || Loss: 0.251 | Top1: 48.50%\n",
      "Privacy Res: 51.50% | 91.50%\n",
      "Privacy Res: 0.00% | 91.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.246 | Top1: 55.50%\n",
      "( 301) Data: 0.02s | Batch: 0.40s || Loss: 0.553 | Top1: 92.00% | Top5: 100.00%\n",
      "Privacy Res: 50.83% | 93.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.248 | Top1: 54.00%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.249 | Top1: 52.00%\n",
      "Privacy Res: 52.83% | 93.00%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.245 | Top1: 56.25%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.247 | Top1: 56.00%\n",
      "Privacy Res: 57.67% | 93.50%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.246 | Top1: 54.00%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.242 | Top1: 59.00%\n",
      "Privacy Res: 55.50% | 89.00%\n",
      "Privacy Res: 0.00% | 91.50%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.241 | Top1: 59.50%\n",
      "( 401) Data: 0.00s | Batch: 0.39s || Loss: 0.506 | Top1: 92.00% | Top5: 100.00%\n",
      "Privacy Res: 56.17% | 92.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.245 | Top1: 56.50%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.245 | Top1: 60.00%\n",
      "Privacy Res: 55.00% | 88.50%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.249 | Top1: 51.75%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.249 | Top1: 53.50%\n",
      "Privacy Res: 53.00% | 90.00%\n",
      "(  70) Data: 0.03s | Batch: 0.37s || Loss: 0.244 | Top1: 55.75%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.246 | Top1: 59.00%\n",
      "Privacy Res: 58.83% | 93.00%\n",
      "Privacy Res: 0.00% | 93.00%\n",
      "(   1) Data: 0.02s | Batch: 0.17s || Loss: 0.572 | Top1: 81.00% | Top5: 100.00%\n",
      "Test Acc: 79.63%\n",
      "\n",
      "Epoch: [19 | 400] LR: 0.050000\n",
      "(   0) Data: 0.03s | Batch: 0.24s || Loss: 0.245 | Top1: 55.00%\n",
      "(   1) Data: 0.02s | Batch: 0.41s || Loss: 0.515 | Top1: 95.00% | Top5: 100.00%\n",
      "Privacy Res: 54.33% | 92.50%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.247 | Top1: 53.25%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.249 | Top1: 53.00%\n",
      "Privacy Res: 51.50% | 94.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.246 | Top1: 54.75%\n",
      "(  60) Data: 0.02s | Batch: 0.31s || Loss: 0.247 | Top1: 53.00%\n",
      "Privacy Res: 52.83% | 91.50%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.244 | Top1: 54.25%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.250 | Top1: 53.50%\n",
      "Privacy Res: 51.50% | 94.50%\n",
      "Privacy Res: 0.00% | 93.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.251 | Top1: 50.00%\n",
      "( 101) Data: 0.02s | Batch: 0.41s || Loss: 0.448 | Top1: 95.00% | Top5: 100.00%\n",
      "Privacy Res: 50.67% | 94.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.244 | Top1: 56.25%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.249 | Top1: 52.00%\n",
      "Privacy Res: 51.17% | 91.00%\n",
      "(  40) Data: 0.03s | Batch: 0.37s || Loss: 0.245 | Top1: 56.50%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.241 | Top1: 56.50%\n",
      "Privacy Res: 53.50% | 93.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.249 | Top1: 51.50%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.251 | Top1: 51.00%\n",
      "Privacy Res: 54.67% | 95.00%\n",
      "Privacy Res: 0.00% | 93.00%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.243 | Top1: 58.50%\n",
      "( 201) Data: 0.02s | Batch: 0.41s || Loss: 0.410 | Top1: 97.00% | Top5: 100.00%\n",
      "Privacy Res: 55.33% | 97.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.246 | Top1: 57.25%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.245 | Top1: 53.00%\n",
      "Privacy Res: 54.17% | 91.50%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.248 | Top1: 53.25%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.247 | Top1: 53.00%\n",
      "Privacy Res: 52.67% | 90.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 51.00%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.247 | Top1: 56.00%\n",
      "Privacy Res: 53.67% | 90.00%\n",
      "Privacy Res: 0.00% | 95.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.248 | Top1: 54.50%\n",
      "( 301) Data: 0.02s | Batch: 0.41s || Loss: 0.582 | Top1: 89.00% | Top5: 100.00%\n",
      "Privacy Res: 54.67% | 92.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.247 | Top1: 55.50%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.246 | Top1: 54.00%\n",
      "Privacy Res: 53.33% | 91.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.251 | Top1: 50.25%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.248 | Top1: 58.00%\n",
      "Privacy Res: 54.83% | 89.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.252 | Top1: 48.00%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.255 | Top1: 46.00%\n",
      "Privacy Res: 52.17% | 92.00%\n",
      "Privacy Res: 0.00% | 94.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.252 | Top1: 50.50%\n",
      "( 401) Data: 0.02s | Batch: 0.41s || Loss: 0.657 | Top1: 90.00% | Top5: 98.00%\n",
      "Privacy Res: 55.67% | 90.50%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.248 | Top1: 55.25%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.244 | Top1: 56.00%\n",
      "Privacy Res: 55.17% | 91.50%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.248 | Top1: 55.00%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.243 | Top1: 58.50%\n",
      "Privacy Res: 54.67% | 92.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.247 | Top1: 53.75%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.248 | Top1: 50.00%\n",
      "Privacy Res: 52.50% | 94.50%\n",
      "Privacy Res: 0.00% | 89.50%\n",
      "(   1) Data: 0.00s | Batch: 0.17s || Loss: 1.005 | Top1: 75.00% | Top5: 96.00%\n",
      "Test Acc: 78.52%\n",
      "\n",
      "Epoch: [20 | 400] LR: 0.050000\n",
      "(   0) Data: 0.04s | Batch: 0.24s || Loss: 0.249 | Top1: 51.50%\n",
      "(   1) Data: 0.02s | Batch: 0.41s || Loss: 0.432 | Top1: 93.00% | Top5: 100.00%\n",
      "Privacy Res: 52.83% | 92.50%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.244 | Top1: 56.25%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.239 | Top1: 59.50%\n",
      "Privacy Res: 59.17% | 94.50%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.244 | Top1: 57.25%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.245 | Top1: 57.50%\n",
      "Privacy Res: 54.67% | 91.50%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.246 | Top1: 55.50%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.251 | Top1: 53.00%\n",
      "Privacy Res: 54.83% | 94.50%\n",
      "Privacy Res: 0.00% | 97.00%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 52.50%\n",
      "( 101) Data: 0.00s | Batch: 0.39s || Loss: 0.445 | Top1: 93.00% | Top5: 100.00%\n",
      "Privacy Res: 52.67% | 93.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.252 | Top1: 49.00%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.246 | Top1: 54.50%\n",
      "Privacy Res: 55.33% | 92.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.247 | Top1: 53.50%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.251 | Top1: 50.00%\n",
      "Privacy Res: 55.17% | 90.50%\n",
      "(  70) Data: 0.03s | Batch: 0.37s || Loss: 0.245 | Top1: 56.00%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.247 | Top1: 52.00%\n",
      "Privacy Res: 52.67% | 92.00%\n",
      "Privacy Res: 0.00% | 96.00%\n",
      "(   0) Data: 0.05s | Batch: 0.31s || Loss: 0.250 | Top1: 52.50%\n",
      "( 201) Data: 0.02s | Batch: 0.41s || Loss: 0.485 | Top1: 94.00% | Top5: 99.00%\n",
      "Privacy Res: 56.67% | 93.50%\n",
      "(  10) Data: 0.03s | Batch: 0.37s || Loss: 0.245 | Top1: 56.50%\n",
      "(  30) Data: 0.04s | Batch: 0.30s || Loss: 0.247 | Top1: 52.00%\n",
      "Privacy Res: 55.50% | 93.50%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.252 | Top1: 50.25%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.251 | Top1: 47.50%\n",
      "Privacy Res: 52.83% | 95.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.248 | Top1: 51.75%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.239 | Top1: 60.50%\n",
      "Privacy Res: 53.83% | 91.00%\n",
      "Privacy Res: 0.00% | 93.00%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 48.50%\n",
      "( 301) Data: 0.02s | Batch: 0.41s || Loss: 0.521 | Top1: 93.00% | Top5: 99.00%\n",
      "Privacy Res: 55.50% | 91.50%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.251 | Top1: 49.50%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.246 | Top1: 55.00%\n",
      "Privacy Res: 59.33% | 89.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.246 | Top1: 55.00%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.250 | Top1: 51.50%\n",
      "Privacy Res: 51.67% | 93.50%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.244 | Top1: 53.50%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.243 | Top1: 57.50%\n",
      "Privacy Res: 56.00% | 91.00%\n",
      "Privacy Res: 0.00% | 89.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.245 | Top1: 57.00%\n",
      "( 401) Data: 0.02s | Batch: 0.41s || Loss: 0.546 | Top1: 90.00% | Top5: 100.00%\n",
      "Privacy Res: 55.33% | 89.50%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.250 | Top1: 52.25%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.244 | Top1: 56.50%\n",
      "Privacy Res: 53.67% | 91.00%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.248 | Top1: 51.50%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.248 | Top1: 56.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Privacy Res: 56.17% | 90.00%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.249 | Top1: 52.25%\n",
      "(  90) Data: 0.01s | Batch: 0.30s || Loss: 0.250 | Top1: 52.00%\n",
      "Privacy Res: 56.17% | 91.50%\n",
      "Privacy Res: 0.00% | 94.00%\n",
      "(   1) Data: 0.06s | Batch: 0.17s || Loss: 0.826 | Top1: 76.00% | Top5: 97.00%\n",
      "Test Acc: 81.06%\n",
      "\n",
      "Epoch: [21 | 400] LR: 0.005000\n",
      "(   0) Data: 0.03s | Batch: 0.23s || Loss: 0.249 | Top1: 52.50%\n",
      "(   1) Data: 0.00s | Batch: 0.39s || Loss: 0.490 | Top1: 93.00% | Top5: 100.00%\n",
      "Privacy Res: 54.67% | 94.50%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.245 | Top1: 57.25%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.245 | Top1: 57.50%\n",
      "Privacy Res: 54.83% | 93.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.246 | Top1: 55.50%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.250 | Top1: 54.00%\n",
      "Privacy Res: 54.33% | 95.50%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.246 | Top1: 54.00%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.247 | Top1: 56.00%\n",
      "Privacy Res: 57.50% | 96.50%\n",
      "Privacy Res: 0.00% | 96.50%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.248 | Top1: 54.00%\n",
      "( 101) Data: 0.02s | Batch: 0.41s || Loss: 0.413 | Top1: 96.00% | Top5: 100.00%\n",
      "Privacy Res: 56.17% | 97.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.242 | Top1: 54.25%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.242 | Top1: 58.50%\n",
      "Privacy Res: 55.83% | 97.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.239 | Top1: 60.25%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.244 | Top1: 51.50%\n",
      "Privacy Res: 56.00% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.242 | Top1: 57.50%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.242 | Top1: 58.00%\n",
      "Privacy Res: 59.67% | 98.00%\n",
      "Privacy Res: 0.00% | 98.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.245 | Top1: 53.50%\n",
      "( 201) Data: 0.02s | Batch: 0.41s || Loss: 0.357 | Top1: 99.00% | Top5: 100.00%\n",
      "Privacy Res: 55.00% | 98.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.242 | Top1: 55.50%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.243 | Top1: 60.50%\n",
      "Privacy Res: 56.67% | 98.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.243 | Top1: 55.50%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.236 | Top1: 60.50%\n",
      "Privacy Res: 57.83% | 96.50%\n",
      "(  70) Data: 0.03s | Batch: 0.37s || Loss: 0.241 | Top1: 57.25%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.244 | Top1: 54.50%\n",
      "Privacy Res: 55.67% | 100.00%\n",
      "Privacy Res: 0.00% | 96.50%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.239 | Top1: 60.50%\n",
      "( 301) Data: 0.02s | Batch: 0.41s || Loss: 0.352 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 59.00% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.242 | Top1: 57.00%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.237 | Top1: 57.50%\n",
      "Privacy Res: 60.33% | 97.00%\n",
      "(  40) Data: 0.03s | Batch: 0.37s || Loss: 0.245 | Top1: 55.00%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.241 | Top1: 57.00%\n",
      "Privacy Res: 56.67% | 98.50%\n",
      "(  70) Data: 0.03s | Batch: 0.37s || Loss: 0.233 | Top1: 64.25%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.236 | Top1: 61.00%\n",
      "Privacy Res: 61.67% | 99.00%\n",
      "Privacy Res: 0.00% | 98.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.232 | Top1: 64.00%\n",
      "( 401) Data: 0.00s | Batch: 0.39s || Loss: 0.409 | Top1: 97.00% | Top5: 100.00%\n",
      "Privacy Res: 64.33% | 98.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.242 | Top1: 55.00%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.241 | Top1: 56.00%\n",
      "Privacy Res: 55.33% | 99.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.241 | Top1: 56.75%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.247 | Top1: 53.50%\n",
      "Privacy Res: 54.83% | 99.50%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.236 | Top1: 60.75%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.239 | Top1: 56.00%\n",
      "Privacy Res: 56.67% | 99.50%\n",
      "Privacy Res: 0.00% | 99.00%\n",
      "(   1) Data: 0.00s | Batch: 0.17s || Loss: 0.535 | Top1: 85.00% | Top5: 98.00%\n",
      "Test Acc: 87.99%\n",
      "\n",
      "Epoch: [22 | 400] LR: 0.005000\n",
      "(   0) Data: 0.03s | Batch: 0.24s || Loss: 0.241 | Top1: 57.50%\n",
      "(   1) Data: 0.02s | Batch: 0.40s || Loss: 0.390 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 57.17% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.237 | Top1: 57.25%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.242 | Top1: 54.00%\n",
      "Privacy Res: 57.00% | 99.50%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.240 | Top1: 55.75%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.238 | Top1: 61.00%\n",
      "Privacy Res: 57.67% | 99.50%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.235 | Top1: 60.50%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.236 | Top1: 58.00%\n",
      "Privacy Res: 60.50% | 99.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.239 | Top1: 56.00%\n",
      "( 101) Data: 0.02s | Batch: 0.41s || Loss: 0.404 | Top1: 99.00% | Top5: 100.00%\n",
      "Privacy Res: 57.50% | 99.50%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.231 | Top1: 63.25%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.245 | Top1: 53.50%\n",
      "Privacy Res: 57.33% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.234 | Top1: 60.00%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.233 | Top1: 63.00%\n",
      "Privacy Res: 60.33% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.238 | Top1: 55.75%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.235 | Top1: 57.00%\n",
      "Privacy Res: 58.67% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.239 | Top1: 58.00%\n",
      "( 201) Data: 0.02s | Batch: 0.41s || Loss: 0.421 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 56.33% | 99.50%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.237 | Top1: 58.50%\n",
      "(  30) Data: 0.02s | Batch: 0.31s || Loss: 0.240 | Top1: 55.00%\n",
      "Privacy Res: 57.33% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.234 | Top1: 59.50%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.241 | Top1: 53.00%\n",
      "Privacy Res: 56.67% | 99.50%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.232 | Top1: 60.00%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.242 | Top1: 53.00%\n",
      "Privacy Res: 56.67% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.225 | Top1: 66.00%\n",
      "( 301) Data: 0.02s | Batch: 0.41s || Loss: 0.463 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 59.33% | 99.50%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.233 | Top1: 59.50%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.238 | Top1: 59.50%\n",
      "Privacy Res: 59.17% | 99.50%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.233 | Top1: 60.00%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.223 | Top1: 63.00%\n",
      "Privacy Res: 59.17% | 99.50%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.241 | Top1: 56.00%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.243 | Top1: 57.50%\n",
      "Privacy Res: 56.33% | 99.50%\n",
      "Privacy Res: 0.00% | 99.00%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.226 | Top1: 62.00%\n",
      "( 401) Data: 0.02s | Batch: 0.41s || Loss: 0.506 | Top1: 99.00% | Top5: 100.00%\n",
      "Privacy Res: 61.00% | 99.50%\n",
      "(  10) Data: 0.03s | Batch: 0.37s || Loss: 0.234 | Top1: 59.00%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.242 | Top1: 53.50%\n",
      "Privacy Res: 56.17% | 99.50%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.237 | Top1: 58.50%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.244 | Top1: 53.00%\n",
      "Privacy Res: 56.33% | 99.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.235 | Top1: 57.50%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.226 | Top1: 63.50%\n",
      "Privacy Res: 58.50% | 99.50%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   1) Data: 0.02s | Batch: 0.17s || Loss: 0.420 | Top1: 89.00% | Top5: 100.00%\n",
      "Test Acc: 88.29%\n",
      "\n",
      "Epoch: [23 | 400] LR: 0.005000\n",
      "(   0) Data: 0.03s | Batch: 0.24s || Loss: 0.228 | Top1: 64.00%\n",
      "(   1) Data: 0.02s | Batch: 0.41s || Loss: 0.503 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 62.17% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.238 | Top1: 59.50%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.232 | Top1: 57.00%\n",
      "Privacy Res: 57.33% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.232 | Top1: 59.25%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.232 | Top1: 60.50%\n",
      "Privacy Res: 59.83% | 100.00%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.228 | Top1: 61.00%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.234 | Top1: 59.00%\n",
      "Privacy Res: 59.33% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.236 | Top1: 58.00%\n",
      "( 101) Data: 0.02s | Batch: 0.41s || Loss: 0.537 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 56.83% | 100.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.223 | Top1: 61.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.234 | Top1: 55.00%\n",
      "Privacy Res: 61.00% | 99.50%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.237 | Top1: 56.25%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.232 | Top1: 61.00%\n",
      "Privacy Res: 59.50% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.237 | Top1: 59.75%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.225 | Top1: 61.00%\n",
      "Privacy Res: 62.33% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.231 | Top1: 60.00%\n",
      "( 201) Data: 0.00s | Batch: 0.40s || Loss: 0.564 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 59.17% | 99.50%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.234 | Top1: 59.50%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.232 | Top1: 60.00%\n",
      "Privacy Res: 58.33% | 100.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.230 | Top1: 61.75%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.231 | Top1: 59.50%\n",
      "Privacy Res: 58.50% | 100.00%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.221 | Top1: 63.75%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.229 | Top1: 60.50%\n",
      "Privacy Res: 60.83% | 100.00%\n",
      "Privacy Res: 0.00% | 99.50%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.231 | Top1: 61.50%\n",
      "( 301) Data: 0.02s | Batch: 0.39s || Loss: 0.566 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 63.17% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.231 | Top1: 59.75%\n",
      "(  30) Data: 0.02s | Batch: 0.31s || Loss: 0.230 | Top1: 61.50%\n",
      "Privacy Res: 61.50% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.233 | Top1: 59.25%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.234 | Top1: 59.50%\n",
      "Privacy Res: 58.00% | 99.50%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.232 | Top1: 58.00%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.226 | Top1: 58.00%\n",
      "Privacy Res: 57.00% | 100.00%\n",
      "Privacy Res: 0.00% | 98.00%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.245 | Top1: 53.50%\n",
      "( 401) Data: 0.02s | Batch: 0.41s || Loss: 0.576 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 57.33% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.229 | Top1: 59.75%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.232 | Top1: 58.00%\n",
      "Privacy Res: 59.50% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.231 | Top1: 59.00%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.221 | Top1: 61.50%\n",
      "Privacy Res: 58.33% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.239 | Top1: 57.75%\n",
      "(  90) Data: 0.02s | Batch: 0.29s || Loss: 0.233 | Top1: 60.50%\n",
      "Privacy Res: 63.00% | 100.00%\n",
      "Privacy Res: 0.00% | 99.50%\n",
      "(   1) Data: 0.02s | Batch: 0.19s || Loss: 0.499 | Top1: 92.00% | Top5: 100.00%\n",
      "Test Acc: 88.20%\n",
      "\n",
      "Epoch: [24 | 400] LR: 0.005000\n",
      "(   0) Data: 0.03s | Batch: 0.24s || Loss: 0.226 | Top1: 61.00%\n",
      "(   1) Data: 0.02s | Batch: 0.39s || Loss: 0.597 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 57.50% | 100.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.237 | Top1: 60.25%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.233 | Top1: 56.50%\n",
      "Privacy Res: 55.50% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.237 | Top1: 59.75%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.246 | Top1: 54.50%\n",
      "Privacy Res: 54.83% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.235 | Top1: 60.00%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.218 | Top1: 63.50%\n",
      "Privacy Res: 64.67% | 99.50%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.214 | Top1: 67.50%\n",
      "( 101) Data: 0.02s | Batch: 0.41s || Loss: 0.570 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 60.67% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.228 | Top1: 63.50%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.233 | Top1: 62.50%\n",
      "Privacy Res: 61.50% | 99.50%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.222 | Top1: 64.00%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.231 | Top1: 62.00%\n",
      "Privacy Res: 60.50% | 99.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.231 | Top1: 61.50%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.235 | Top1: 56.50%\n",
      "Privacy Res: 61.17% | 99.50%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.229 | Top1: 61.00%\n",
      "( 201) Data: 0.02s | Batch: 0.41s || Loss: 0.557 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 58.00% | 100.00%\n",
      "(  10) Data: 0.04s | Batch: 0.37s || Loss: 0.233 | Top1: 59.75%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.228 | Top1: 60.50%\n",
      "Privacy Res: 61.50% | 100.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.230 | Top1: 61.50%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.229 | Top1: 61.00%\n",
      "Privacy Res: 61.00% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.233 | Top1: 58.75%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.232 | Top1: 58.50%\n",
      "Privacy Res: 58.00% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.233 | Top1: 63.00%\n",
      "( 301) Data: 0.00s | Batch: 0.39s || Loss: 0.550 | Top1: 99.00% | Top5: 100.00%\n",
      "Privacy Res: 62.50% | 99.50%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.228 | Top1: 61.00%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.225 | Top1: 64.00%\n",
      "Privacy Res: 61.50% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.236 | Top1: 59.50%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.223 | Top1: 63.00%\n",
      "Privacy Res: 60.67% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.234 | Top1: 57.25%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.240 | Top1: 56.50%\n",
      "Privacy Res: 59.33% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.225 | Top1: 61.50%\n",
      "( 401) Data: 0.02s | Batch: 0.39s || Loss: 0.493 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 58.17% | 100.00%\n",
      "(  10) Data: 0.01s | Batch: 0.37s || Loss: 0.247 | Top1: 54.00%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.230 | Top1: 61.00%\n",
      "Privacy Res: 59.83% | 100.00%\n",
      "(  40) Data: 0.03s | Batch: 0.37s || Loss: 0.225 | Top1: 63.00%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.224 | Top1: 61.00%\n",
      "Privacy Res: 60.83% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.239 | Top1: 54.50%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.239 | Top1: 58.50%\n",
      "Privacy Res: 57.17% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   1) Data: 0.02s | Batch: 0.18s || Loss: 0.400 | Top1: 92.00% | Top5: 100.00%\n",
      "Test Acc: 88.27%\n",
      "\n",
      "Epoch: [25 | 400] LR: 0.005000\n",
      "(   0) Data: 0.03s | Batch: 0.23s || Loss: 0.240 | Top1: 57.50%\n",
      "(   1) Data: 0.02s | Batch: 0.41s || Loss: 0.454 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 60.17% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.227 | Top1: 61.75%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.245 | Top1: 55.00%\n",
      "Privacy Res: 57.67% | 100.00%\n",
      "(  40) Data: 0.03s | Batch: 0.37s || Loss: 0.228 | Top1: 59.75%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.228 | Top1: 58.50%\n",
      "Privacy Res: 58.67% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.225 | Top1: 60.75%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.223 | Top1: 61.00%\n",
      "Privacy Res: 60.50% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.234 | Top1: 63.50%\n",
      "( 101) Data: 0.02s | Batch: 0.41s || Loss: 0.448 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 61.00% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.231 | Top1: 60.75%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.228 | Top1: 60.00%\n",
      "Privacy Res: 59.67% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.229 | Top1: 62.25%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.224 | Top1: 60.00%\n",
      "Privacy Res: 60.67% | 99.50%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.224 | Top1: 63.25%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.225 | Top1: 60.00%\n",
      "Privacy Res: 61.67% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.234 | Top1: 61.00%\n",
      "( 201) Data: 0.00s | Batch: 0.39s || Loss: 0.439 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 59.00% | 100.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.226 | Top1: 61.75%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.225 | Top1: 60.00%\n",
      "Privacy Res: 60.17% | 99.50%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.230 | Top1: 60.50%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.230 | Top1: 59.00%\n",
      "Privacy Res: 62.17% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.235 | Top1: 58.00%\n",
      "(  90) Data: 0.02s | Batch: 0.29s || Loss: 0.236 | Top1: 59.00%\n",
      "Privacy Res: 58.33% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.254 | Top1: 55.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 301) Data: 0.03s | Batch: 0.41s || Loss: 0.421 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 56.67% | 100.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.237 | Top1: 57.00%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.216 | Top1: 64.00%\n",
      "Privacy Res: 61.67% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.228 | Top1: 61.75%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.216 | Top1: 66.00%\n",
      "Privacy Res: 61.67% | 99.50%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.219 | Top1: 65.50%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.225 | Top1: 62.00%\n",
      "Privacy Res: 62.33% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.05s | Batch: 0.31s || Loss: 0.261 | Top1: 51.50%\n",
      "( 401) Data: 0.02s | Batch: 0.39s || Loss: 0.440 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 56.67% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.240 | Top1: 58.00%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.223 | Top1: 61.50%\n",
      "Privacy Res: 60.67% | 100.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.230 | Top1: 61.75%\n",
      "(  60) Data: 0.02s | Batch: 0.29s || Loss: 0.226 | Top1: 60.00%\n",
      "Privacy Res: 58.67% | 100.00%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.236 | Top1: 58.25%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.229 | Top1: 59.00%\n",
      "Privacy Res: 60.00% | 100.00%\n",
      "Privacy Res: 0.00% | 99.50%\n",
      "(   1) Data: 0.02s | Batch: 0.17s || Loss: 0.478 | Top1: 91.00% | Top5: 98.00%\n",
      "Test Acc: 88.11%\n",
      "\n",
      "Epoch: [26 | 400] LR: 0.005000\n",
      "(   0) Data: 0.03s | Batch: 0.24s || Loss: 0.242 | Top1: 58.50%\n",
      "(   1) Data: 0.02s | Batch: 0.41s || Loss: 0.424 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 59.17% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.229 | Top1: 62.25%\n",
      "(  30) Data: 0.05s | Batch: 0.31s || Loss: 0.235 | Top1: 58.00%\n",
      "Privacy Res: 59.83% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.221 | Top1: 63.50%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.231 | Top1: 59.00%\n",
      "Privacy Res: 61.00% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.219 | Top1: 64.00%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.231 | Top1: 60.00%\n",
      "Privacy Res: 58.83% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.240 | Top1: 57.50%\n",
      "( 101) Data: 0.02s | Batch: 0.41s || Loss: 0.414 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 57.67% | 100.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.237 | Top1: 58.25%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.237 | Top1: 58.00%\n",
      "Privacy Res: 59.50% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.226 | Top1: 60.00%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.215 | Top1: 64.50%\n",
      "Privacy Res: 60.50% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.222 | Top1: 61.00%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.229 | Top1: 60.50%\n",
      "Privacy Res: 60.33% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.248 | Top1: 57.00%\n",
      "( 201) Data: 0.02s | Batch: 0.41s || Loss: 0.438 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 56.33% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.230 | Top1: 61.00%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.230 | Top1: 61.00%\n",
      "Privacy Res: 60.67% | 99.50%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.226 | Top1: 61.75%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.228 | Top1: 62.50%\n",
      "Privacy Res: 62.50% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.236 | Top1: 56.75%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.232 | Top1: 53.50%\n",
      "Privacy Res: 58.67% | 99.50%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.255 | Top1: 56.50%\n",
      "( 301) Data: 0.00s | Batch: 0.39s || Loss: 0.435 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 56.17% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.238 | Top1: 58.75%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.222 | Top1: 63.00%\n",
      "Privacy Res: 61.67% | 100.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.226 | Top1: 60.25%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.221 | Top1: 63.00%\n",
      "Privacy Res: 63.00% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.225 | Top1: 62.75%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.217 | Top1: 65.50%\n",
      "Privacy Res: 61.17% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.239 | Top1: 57.00%\n",
      "( 401) Data: 0.02s | Batch: 0.41s || Loss: 0.396 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 60.00% | 99.50%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.225 | Top1: 62.25%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.240 | Top1: 55.50%\n",
      "Privacy Res: 59.17% | 99.50%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.219 | Top1: 64.50%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.227 | Top1: 60.50%\n",
      "Privacy Res: 62.83% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.220 | Top1: 62.25%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.228 | Top1: 60.00%\n",
      "Privacy Res: 61.00% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   1) Data: 0.02s | Batch: 0.17s || Loss: 0.507 | Top1: 87.00% | Top5: 99.00%\n",
      "Test Acc: 87.97%\n",
      "\n",
      "Epoch: [27 | 400] LR: 0.005000\n",
      "(   0) Data: 0.02s | Batch: 0.23s || Loss: 0.240 | Top1: 59.50%\n",
      "(   1) Data: 0.02s | Batch: 0.41s || Loss: 0.417 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 60.17% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.232 | Top1: 59.25%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.232 | Top1: 56.50%\n",
      "Privacy Res: 62.00% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.229 | Top1: 60.75%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.239 | Top1: 55.00%\n",
      "Privacy Res: 57.00% | 100.00%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.225 | Top1: 60.00%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.232 | Top1: 59.50%\n",
      "Privacy Res: 58.17% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.226 | Top1: 60.00%\n",
      "( 101) Data: 0.02s | Batch: 0.41s || Loss: 0.418 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 59.17% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.228 | Top1: 61.25%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.221 | Top1: 64.50%\n",
      "Privacy Res: 61.83% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.225 | Top1: 61.25%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.228 | Top1: 60.00%\n",
      "Privacy Res: 60.00% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.220 | Top1: 63.00%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.209 | Top1: 64.50%\n",
      "Privacy Res: 62.00% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.32s || Loss: 0.217 | Top1: 63.00%\n",
      "( 201) Data: 0.02s | Batch: 0.41s || Loss: 0.431 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 60.33% | 100.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.220 | Top1: 62.25%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.216 | Top1: 61.50%\n",
      "Privacy Res: 59.50% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.219 | Top1: 63.25%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.223 | Top1: 61.00%\n",
      "Privacy Res: 61.83% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.226 | Top1: 59.50%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.227 | Top1: 61.50%\n",
      "Privacy Res: 58.50% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.229 | Top1: 62.50%\n",
      "( 301) Data: 0.02s | Batch: 0.41s || Loss: 0.433 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 58.67% | 100.00%\n",
      "(  10) Data: 0.03s | Batch: 0.37s || Loss: 0.230 | Top1: 61.00%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.230 | Top1: 60.00%\n",
      "Privacy Res: 61.17% | 99.50%\n",
      "(  40) Data: 0.03s | Batch: 0.37s || Loss: 0.221 | Top1: 60.75%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.231 | Top1: 57.00%\n",
      "Privacy Res: 59.17% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.220 | Top1: 62.50%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.210 | Top1: 68.00%\n",
      "Privacy Res: 63.17% | 99.50%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.238 | Top1: 59.50%\n",
      "( 401) Data: 0.02s | Batch: 0.41s || Loss: 0.431 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 60.83% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.231 | Top1: 60.00%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.245 | Top1: 55.50%\n",
      "Privacy Res: 60.50% | 100.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.222 | Top1: 62.25%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.212 | Top1: 64.00%\n",
      "Privacy Res: 65.83% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.232 | Top1: 58.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.226 | Top1: 58.50%\n",
      "Privacy Res: 59.00% | 100.00%\n",
      "Privacy Res: 0.00% | 99.50%\n",
      "(   1) Data: 0.02s | Batch: 0.19s || Loss: 0.477 | Top1: 93.00% | Top5: 97.00%\n",
      "Test Acc: 87.91%\n",
      "\n",
      "Epoch: [28 | 400] LR: 0.005000\n",
      "(   0) Data: 0.03s | Batch: 0.23s || Loss: 0.240 | Top1: 59.00%\n",
      "(   1) Data: 0.02s | Batch: 0.41s || Loss: 0.415 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 58.67% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.221 | Top1: 63.00%\n",
      "(  30) Data: 0.02s | Batch: 0.31s || Loss: 0.227 | Top1: 60.50%\n",
      "Privacy Res: 59.00% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.232 | Top1: 58.50%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.230 | Top1: 60.00%\n",
      "Privacy Res: 61.17% | 100.00%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.225 | Top1: 61.75%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.233 | Top1: 59.50%\n",
      "Privacy Res: 60.50% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.225 | Top1: 63.00%\n",
      "( 101) Data: 0.02s | Batch: 0.41s || Loss: 0.401 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 60.50% | 99.50%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.228 | Top1: 59.25%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.223 | Top1: 61.00%\n",
      "Privacy Res: 60.17% | 99.50%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.241 | Top1: 55.50%\n",
      "(  60) Data: 0.04s | Batch: 0.31s || Loss: 0.223 | Top1: 61.50%\n",
      "Privacy Res: 60.67% | 100.00%\n",
      "(  70) Data: 0.01s | Batch: 0.37s || Loss: 0.217 | Top1: 62.75%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.233 | Top1: 61.00%\n",
      "Privacy Res: 61.00% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.239 | Top1: 58.50%\n",
      "( 201) Data: 0.02s | Batch: 0.41s || Loss: 0.413 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 56.00% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.232 | Top1: 60.75%\n",
      "(  30) Data: 0.03s | Batch: 0.32s || Loss: 0.221 | Top1: 60.50%\n",
      "Privacy Res: 63.17% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.226 | Top1: 60.75%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.234 | Top1: 58.50%\n",
      "Privacy Res: 60.00% | 100.00%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.224 | Top1: 59.75%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.225 | Top1: 60.50%\n",
      "Privacy Res: 61.17% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.249 | Top1: 53.50%\n",
      "( 301) Data: 0.02s | Batch: 0.41s || Loss: 0.400 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 56.00% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.217 | Top1: 64.50%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.238 | Top1: 54.50%\n",
      "Privacy Res: 59.00% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.231 | Top1: 57.00%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.231 | Top1: 61.50%\n",
      "Privacy Res: 61.67% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.236 | Top1: 58.25%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.219 | Top1: 63.00%\n",
      "Privacy Res: 59.50% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.237 | Top1: 59.50%\n",
      "( 401) Data: 0.00s | Batch: 0.39s || Loss: 0.402 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 58.17% | 100.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.233 | Top1: 58.50%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.231 | Top1: 60.50%\n",
      "Privacy Res: 61.00% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.224 | Top1: 61.00%\n",
      "(  60) Data: 0.02s | Batch: 0.31s || Loss: 0.213 | Top1: 62.50%\n",
      "Privacy Res: 62.33% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.225 | Top1: 61.00%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.228 | Top1: 61.00%\n",
      "Privacy Res: 60.00% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   1) Data: 0.02s | Batch: 0.17s || Loss: 0.326 | Top1: 91.00% | Top5: 100.00%\n",
      "Test Acc: 87.97%\n",
      "\n",
      "Epoch: [29 | 400] LR: 0.005000\n",
      "(   0) Data: 0.02s | Batch: 0.23s || Loss: 0.240 | Top1: 62.00%\n",
      "(   1) Data: 0.02s | Batch: 0.41s || Loss: 0.392 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 60.17% | 100.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.233 | Top1: 58.50%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.230 | Top1: 58.50%\n",
      "Privacy Res: 63.00% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.216 | Top1: 64.75%\n",
      "(  60) Data: 0.05s | Batch: 0.30s || Loss: 0.216 | Top1: 63.50%\n",
      "Privacy Res: 61.33% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.223 | Top1: 63.00%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.210 | Top1: 66.00%\n",
      "Privacy Res: 63.17% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.237 | Top1: 61.00%\n",
      "( 101) Data: 0.02s | Batch: 0.41s || Loss: 0.380 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 62.50% | 100.00%\n",
      "(  10) Data: 0.03s | Batch: 0.37s || Loss: 0.228 | Top1: 60.50%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.229 | Top1: 60.00%\n",
      "Privacy Res: 62.50% | 99.50%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.208 | Top1: 66.50%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.220 | Top1: 61.50%\n",
      "Privacy Res: 62.33% | 100.00%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.224 | Top1: 61.00%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.226 | Top1: 63.50%\n",
      "Privacy Res: 63.83% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.257 | Top1: 57.00%\n",
      "( 201) Data: 0.02s | Batch: 0.40s || Loss: 0.353 | Top1: 99.00% | Top5: 100.00%\n",
      "Privacy Res: 57.83% | 99.50%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.239 | Top1: 57.50%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.222 | Top1: 63.00%\n",
      "Privacy Res: 61.50% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.223 | Top1: 63.00%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.235 | Top1: 58.50%\n",
      "Privacy Res: 60.33% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.220 | Top1: 63.50%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.223 | Top1: 62.50%\n",
      "Privacy Res: 63.00% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.254 | Top1: 55.00%\n",
      "( 301) Data: 0.02s | Batch: 0.41s || Loss: 0.410 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 58.50% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.231 | Top1: 61.50%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.220 | Top1: 64.00%\n",
      "Privacy Res: 62.17% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.225 | Top1: 61.50%\n",
      "(  60) Data: 0.02s | Batch: 0.31s || Loss: 0.226 | Top1: 60.50%\n",
      "Privacy Res: 60.50% | 100.00%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.223 | Top1: 61.25%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.207 | Top1: 66.50%\n",
      "Privacy Res: 63.67% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.237 | Top1: 61.00%\n",
      "( 401) Data: 0.02s | Batch: 0.41s || Loss: 0.412 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 60.17% | 100.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.237 | Top1: 56.75%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.216 | Top1: 63.00%\n",
      "Privacy Res: 65.33% | 100.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.230 | Top1: 60.00%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.221 | Top1: 62.00%\n",
      "Privacy Res: 61.33% | 99.50%\n",
      "(  70) Data: 0.03s | Batch: 0.37s || Loss: 0.223 | Top1: 61.25%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.226 | Top1: 61.50%\n",
      "Privacy Res: 62.00% | 100.00%\n",
      "Privacy Res: 0.00% | 99.50%\n",
      "(   1) Data: 0.02s | Batch: 0.17s || Loss: 0.407 | Top1: 88.00% | Top5: 100.00%\n",
      "Test Acc: 87.93%\n",
      "\n",
      "Epoch: [30 | 400] LR: 0.005000\n",
      "(   0) Data: 0.02s | Batch: 0.22s || Loss: 0.224 | Top1: 64.00%\n",
      "(   1) Data: 0.02s | Batch: 0.41s || Loss: 0.420 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 58.50% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.220 | Top1: 63.25%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.241 | Top1: 56.00%\n",
      "Privacy Res: 62.33% | 100.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.224 | Top1: 62.00%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.212 | Top1: 64.50%\n",
      "Privacy Res: 63.33% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.218 | Top1: 64.75%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.233 | Top1: 59.50%\n",
      "Privacy Res: 60.00% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.225 | Top1: 61.00%\n",
      "( 101) Data: 0.02s | Batch: 0.41s || Loss: 0.404 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 58.33% | 100.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.225 | Top1: 62.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.234 | Top1: 60.00%\n",
      "Privacy Res: 62.00% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.37s || Loss: 0.223 | Top1: 61.50%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.224 | Top1: 60.00%\n",
      "Privacy Res: 57.83% | 99.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.218 | Top1: 62.75%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.228 | Top1: 63.00%\n",
      "Privacy Res: 61.17% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.229 | Top1: 62.00%\n",
      "( 201) Data: 0.02s | Batch: 0.41s || Loss: 0.403 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 60.00% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.218 | Top1: 62.00%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.220 | Top1: 64.00%\n",
      "Privacy Res: 63.83% | 99.50%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.216 | Top1: 63.00%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.218 | Top1: 64.50%\n",
      "Privacy Res: 63.33% | 100.00%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.221 | Top1: 61.75%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.207 | Top1: 65.00%\n",
      "Privacy Res: 64.17% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.241 | Top1: 55.50%\n",
      "( 301) Data: 0.02s | Batch: 0.41s || Loss: 0.429 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 59.83% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.235 | Top1: 58.00%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.212 | Top1: 63.50%\n",
      "Privacy Res: 61.67% | 100.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.212 | Top1: 64.25%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.221 | Top1: 63.50%\n",
      "Privacy Res: 62.33% | 100.00%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.220 | Top1: 62.25%\n",
      "(  90) Data: 0.04s | Batch: 0.31s || Loss: 0.228 | Top1: 59.00%\n",
      "Privacy Res: 59.33% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.227 | Top1: 62.00%\n",
      "( 401) Data: 0.02s | Batch: 0.41s || Loss: 0.397 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 58.50% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.227 | Top1: 60.75%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.213 | Top1: 65.00%\n",
      "Privacy Res: 61.67% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.229 | Top1: 60.00%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.220 | Top1: 62.50%\n",
      "Privacy Res: 65.33% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.219 | Top1: 62.75%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.218 | Top1: 61.50%\n",
      "Privacy Res: 61.00% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   1) Data: 0.02s | Batch: 0.17s || Loss: 0.502 | Top1: 90.00% | Top5: 96.00%\n",
      "Test Acc: 87.85%\n",
      "\n",
      "Epoch: [31 | 400] LR: 0.005000\n",
      "(   0) Data: 0.03s | Batch: 0.25s || Loss: 0.240 | Top1: 58.50%\n",
      "(   1) Data: 0.02s | Batch: 0.40s || Loss: 0.373 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 59.83% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.221 | Top1: 62.75%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.221 | Top1: 64.50%\n",
      "Privacy Res: 60.00% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.222 | Top1: 62.00%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.226 | Top1: 62.00%\n",
      "Privacy Res: 62.33% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.228 | Top1: 61.25%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.231 | Top1: 59.50%\n",
      "Privacy Res: 61.50% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.231 | Top1: 60.50%\n",
      "( 101) Data: 0.00s | Batch: 0.39s || Loss: 0.392 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 60.00% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.234 | Top1: 57.25%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.219 | Top1: 62.00%\n",
      "Privacy Res: 62.50% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.228 | Top1: 60.00%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.228 | Top1: 61.50%\n",
      "Privacy Res: 61.83% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.221 | Top1: 62.00%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.240 | Top1: 57.50%\n",
      "Privacy Res: 61.67% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.02s | Batch: 0.31s || Loss: 0.235 | Top1: 60.00%\n",
      "( 201) Data: 0.02s | Batch: 0.41s || Loss: 0.393 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 60.67% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.223 | Top1: 61.75%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.230 | Top1: 57.00%\n",
      "Privacy Res: 61.33% | 100.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.232 | Top1: 57.75%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.210 | Top1: 66.50%\n",
      "Privacy Res: 62.50% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.224 | Top1: 61.50%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.222 | Top1: 61.00%\n",
      "Privacy Res: 60.00% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.230 | Top1: 58.00%\n",
      "( 301) Data: 0.02s | Batch: 0.41s || Loss: 0.387 | Top1: 99.00% | Top5: 100.00%\n",
      "Privacy Res: 61.17% | 99.50%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.229 | Top1: 60.50%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.208 | Top1: 68.00%\n",
      "Privacy Res: 62.50% | 100.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.223 | Top1: 60.50%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.221 | Top1: 63.00%\n",
      "Privacy Res: 61.33% | 100.00%\n",
      "(  70) Data: 0.04s | Batch: 0.38s || Loss: 0.224 | Top1: 59.75%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.216 | Top1: 63.50%\n",
      "Privacy Res: 61.83% | 99.50%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.231 | Top1: 61.50%\n",
      "( 401) Data: 0.00s | Batch: 0.39s || Loss: 0.378 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 59.17% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.234 | Top1: 60.00%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.226 | Top1: 60.50%\n",
      "Privacy Res: 57.83% | 100.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.233 | Top1: 58.75%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.227 | Top1: 62.50%\n",
      "Privacy Res: 59.83% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.225 | Top1: 61.50%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.224 | Top1: 62.00%\n",
      "Privacy Res: 63.17% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   1) Data: 0.02s | Batch: 0.19s || Loss: 0.532 | Top1: 81.00% | Top5: 96.00%\n",
      "Test Acc: 87.79%\n",
      "\n",
      "Epoch: [32 | 400] LR: 0.005000\n",
      "(   0) Data: 0.03s | Batch: 0.24s || Loss: 0.223 | Top1: 61.50%\n",
      "(   1) Data: 0.02s | Batch: 0.41s || Loss: 0.381 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 60.83% | 100.00%\n",
      "(  10) Data: 0.03s | Batch: 0.37s || Loss: 0.219 | Top1: 62.75%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.222 | Top1: 62.00%\n",
      "Privacy Res: 59.83% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.224 | Top1: 60.25%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.231 | Top1: 62.50%\n",
      "Privacy Res: 61.50% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.224 | Top1: 60.75%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.222 | Top1: 61.50%\n",
      "Privacy Res: 58.83% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.30s || Loss: 0.249 | Top1: 55.50%\n",
      "( 101) Data: 0.02s | Batch: 0.41s || Loss: 0.386 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 56.67% | 100.00%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.233 | Top1: 59.00%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.222 | Top1: 60.00%\n",
      "Privacy Res: 61.50% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.231 | Top1: 59.50%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.221 | Top1: 62.50%\n",
      "Privacy Res: 62.67% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.214 | Top1: 64.00%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.207 | Top1: 67.50%\n",
      "Privacy Res: 64.17% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.263 | Top1: 56.50%\n",
      "( 201) Data: 0.02s | Batch: 0.41s || Loss: 0.373 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 57.67% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.231 | Top1: 59.50%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.219 | Top1: 62.00%\n",
      "Privacy Res: 63.33% | 99.50%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.220 | Top1: 61.50%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.219 | Top1: 62.00%\n",
      "Privacy Res: 64.67% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.211 | Top1: 65.25%\n",
      "(  90) Data: 0.02s | Batch: 0.30s || Loss: 0.218 | Top1: 61.00%\n",
      "Privacy Res: 60.00% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.244 | Top1: 56.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 301) Data: 0.02s | Batch: 0.41s || Loss: 0.410 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 58.33% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.236 | Top1: 56.50%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.221 | Top1: 62.50%\n",
      "Privacy Res: 62.17% | 100.00%\n",
      "(  40) Data: 0.03s | Batch: 0.38s || Loss: 0.222 | Top1: 62.25%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.223 | Top1: 63.00%\n",
      "Privacy Res: 62.33% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.37s || Loss: 0.227 | Top1: 60.75%\n",
      "(  90) Data: 0.03s | Batch: 0.31s || Loss: 0.216 | Top1: 65.50%\n",
      "Privacy Res: 63.33% | 100.00%\n",
      "Privacy Res: 0.00% | 99.50%\n",
      "(   0) Data: 0.03s | Batch: 0.31s || Loss: 0.220 | Top1: 63.50%\n",
      "( 401) Data: 0.02s | Batch: 0.41s || Loss: 0.401 | Top1: 99.00% | Top5: 100.00%\n",
      "Privacy Res: 63.00% | 99.50%\n",
      "(  10) Data: 0.03s | Batch: 0.38s || Loss: 0.220 | Top1: 62.00%\n",
      "(  30) Data: 0.02s | Batch: 0.30s || Loss: 0.219 | Top1: 62.50%\n",
      "Privacy Res: 60.33% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.221 | Top1: 61.00%\n",
      "(  60) Data: 0.03s | Batch: 0.31s || Loss: 0.226 | Top1: 61.50%\n",
      "Privacy Res: 62.50% | 100.00%\n",
      "(  70) Data: 0.02s | Batch: 0.38s || Loss: 0.230 | Top1: 59.25%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.218 | Top1: 61.00%\n",
      "Privacy Res: 61.67% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   1) Data: 0.00s | Batch: 0.17s || Loss: 0.512 | Top1: 86.00% | Top5: 99.00%\n",
      "Test Acc: 87.70%\n",
      "\n",
      "Epoch: [33 | 400] LR: 0.005000\n",
      "(   0) Data: 0.03s | Batch: 0.24s || Loss: 0.229 | Top1: 60.50%\n",
      "(   1) Data: 0.02s | Batch: 0.41s || Loss: 0.380 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 62.17% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.227 | Top1: 60.00%\n",
      "(  30) Data: 0.03s | Batch: 0.30s || Loss: 0.222 | Top1: 62.00%\n",
      "Privacy Res: 64.00% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.215 | Top1: 65.00%\n",
      "(  60) Data: 0.02s | Batch: 0.30s || Loss: 0.206 | Top1: 67.00%\n",
      "Privacy Res: 63.17% | 99.50%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.214 | Top1: 62.50%\n",
      "(  90) Data: 0.03s | Batch: 0.30s || Loss: 0.236 | Top1: 57.50%\n",
      "Privacy Res: 61.33% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.243 | Top1: 57.50%\n",
      "( 101) Data: 0.00s | Batch: 0.39s || Loss: 0.396 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 58.17% | 100.00%\n",
      "(  10) Data: 0.02s | Batch: 0.38s || Loss: 0.228 | Top1: 60.25%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.224 | Top1: 63.00%\n",
      "Privacy Res: 60.67% | 100.00%\n",
      "(  40) Data: 0.02s | Batch: 0.38s || Loss: 0.209 | Top1: 66.25%\n",
      "(  60) Data: 0.03s | Batch: 0.30s || Loss: 0.238 | Top1: 57.00%\n",
      "Privacy Res: 59.83% | 100.00%\n",
      "(  70) Data: 0.03s | Batch: 0.38s || Loss: 0.218 | Top1: 63.00%\n",
      "(  90) Data: 0.02s | Batch: 0.31s || Loss: 0.230 | Top1: 59.50%\n",
      "Privacy Res: 59.83% | 100.00%\n",
      "Privacy Res: 0.00% | 100.00%\n",
      "(   0) Data: 0.02s | Batch: 0.30s || Loss: 0.233 | Top1: 60.00%\n",
      "( 201) Data: 0.02s | Batch: 0.41s || Loss: 0.386 | Top1: 100.00% | Top5: 100.00%\n",
      "Privacy Res: 62.50% | 99.50%\n",
      "(  10) Data: 0.02s | Batch: 0.37s || Loss: 0.225 | Top1: 61.00%\n",
      "(  30) Data: 0.03s | Batch: 0.31s || Loss: 0.212 | Top1: 64.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23228/1687127556.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m             )\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             train_loss, train_acc = train_privately(\n\u001b[0m\u001b[0;32m     25\u001b[0m                 \u001b[0mtrain_enum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minference_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             )\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23228/1269984579.py\u001b[0m in \u001b[0;36mtrain_privately\u001b[1;34m(trainloader, model, inference_model, criterion, optimizer, use_cuda, num_batches, alpha)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mfirst_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;31m# measure data loading time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mdata_time\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \"\"\"\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m     \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "if not os.path.isdir(checkpoint_path):\n",
    "    mkdir_p(checkpoint_path)\n",
    "\n",
    "is_best = False\n",
    "best_acc = 0.0\n",
    "start_epoch = 0\n",
    "\n",
    "# Train and val\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    print(f'\\nEpoch: [{epoch + 1:d} | {EPOCHS:d}] LR: {state[\"lr\"]:f}')\n",
    "\n",
    "    train_enum = enumerate(trainloader)\n",
    "    train_private_enum = enumerate(zip(trainloader_private, testloader))\n",
    "    for i in range(500 // 2):\n",
    "\n",
    "        if epoch > 3:\n",
    "            privacy_loss, privacy_acc = privacy_train(\n",
    "                train_private_enum, model, inference_model, criterion_attack, optimizer_mem, use_cuda, 1\n",
    "            )\n",
    "\n",
    "            train_loss, train_acc = train_privately(\n",
    "                train_enum, model, inference_model, criterion, optimizer, use_cuda, 1, 1\n",
    "            )\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print(f'Privacy Res: {privacy_acc * 100:.2f}% | {train_acc * 100:.2f}%')\n",
    "\n",
    "            if (i + 1) % 50 == 0:\n",
    "                train_private_enum = enumerate(zip(trainloader_private, testloader))\n",
    "        else:\n",
    "            train_loss, train_acc = train_privately(\n",
    "                train_enum, model, inference_model, criterion, optimizer, use_cuda, 1000, 0\n",
    "            )\n",
    "\n",
    "            break\n",
    "\n",
    "    test_loss, test_acc = test(testloader, model, criterion, use_cuda)\n",
    "\n",
    "    print(f'Test Acc: {test_acc * 100:.2f}%')\n",
    "\n",
    "    # save model\n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    save_checkpoint({\n",
    "        'epochz': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'acc': test_acc,\n",
    "        'best_acc': best_acc,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, False, checkpoint=checkpoint_path, filename='epoch%d' % epoch)\n",
    "\n",
    "print(f'Best acc: {best_acc * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ff879c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNext(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): ResNextBottleNeckC(\n",
      "      (split_transforms): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResNextBottleNeckC(\n",
      "      (split_transforms): Sequential(\n",
      "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): ResNextBottleNeckC(\n",
      "      (split_transforms): Sequential(\n",
      "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): ResNextBottleNeckC(\n",
      "      (split_transforms): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResNextBottleNeckC(\n",
      "      (split_transforms): Sequential(\n",
      "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): ResNextBottleNeckC(\n",
      "      (split_transforms): Sequential(\n",
      "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (3): ResNextBottleNeckC(\n",
      "      (split_transforms): Sequential(\n",
      "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): ResNextBottleNeckC(\n",
      "      (split_transforms): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResNextBottleNeckC(\n",
      "      (split_transforms): Sequential(\n",
      "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): ResNextBottleNeckC(\n",
      "      (split_transforms): Sequential(\n",
      "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (3): ResNextBottleNeckC(\n",
      "      (split_transforms): Sequential(\n",
      "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (4): ResNextBottleNeckC(\n",
      "      (split_transforms): Sequential(\n",
      "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (5): ResNextBottleNeckC(\n",
      "      (split_transforms): Sequential(\n",
      "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): ResNextBottleNeckC(\n",
      "      (split_transforms): Sequential(\n",
      "        (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResNextBottleNeckC(\n",
      "      (split_transforms): Sequential(\n",
      "        (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): ResNextBottleNeckC(\n",
      "      (split_transforms): Sequential(\n",
      "        (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (avg): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc1): Linear(in_features=2048, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "baa2d2fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNext:\n\tMissing key(s) in state_dict: \"conv1.0.weight\", \"conv1.1.weight\", \"conv1.1.bias\", \"conv1.1.running_mean\", \"conv1.1.running_var\", \"conv2.0.split_transforms.0.weight\", \"conv2.0.split_transforms.1.weight\", \"conv2.0.split_transforms.1.bias\", \"conv2.0.split_transforms.1.running_mean\", \"conv2.0.split_transforms.1.running_var\", \"conv2.0.split_transforms.3.weight\", \"conv2.0.split_transforms.4.weight\", \"conv2.0.split_transforms.4.bias\", \"conv2.0.split_transforms.4.running_mean\", \"conv2.0.split_transforms.4.running_var\", \"conv2.0.split_transforms.6.weight\", \"conv2.0.split_transforms.7.weight\", \"conv2.0.split_transforms.7.bias\", \"conv2.0.split_transforms.7.running_mean\", \"conv2.0.split_transforms.7.running_var\", \"conv2.0.shortcut.0.weight\", \"conv2.0.shortcut.1.weight\", \"conv2.0.shortcut.1.bias\", \"conv2.0.shortcut.1.running_mean\", \"conv2.0.shortcut.1.running_var\", \"conv2.1.split_transforms.0.weight\", \"conv2.1.split_transforms.1.weight\", \"conv2.1.split_transforms.1.bias\", \"conv2.1.split_transforms.1.running_mean\", \"conv2.1.split_transforms.1.running_var\", \"conv2.1.split_transforms.3.weight\", \"conv2.1.split_transforms.4.weight\", \"conv2.1.split_transforms.4.bias\", \"conv2.1.split_transforms.4.running_mean\", \"conv2.1.split_transforms.4.running_var\", \"conv2.1.split_transforms.6.weight\", \"conv2.1.split_transforms.7.weight\", \"conv2.1.split_transforms.7.bias\", \"conv2.1.split_transforms.7.running_mean\", \"conv2.1.split_transforms.7.running_var\", \"conv2.2.split_transforms.0.weight\", \"conv2.2.split_transforms.1.weight\", \"conv2.2.split_transforms.1.bias\", \"conv2.2.split_transforms.1.running_mean\", \"conv2.2.split_transforms.1.running_var\", \"conv2.2.split_transforms.3.weight\", \"conv2.2.split_transforms.4.weight\", \"conv2.2.split_transforms.4.bias\", \"conv2.2.split_transforms.4.running_mean\", \"conv2.2.split_transforms.4.running_var\", \"conv2.2.split_transforms.6.weight\", \"conv2.2.split_transforms.7.weight\", \"conv2.2.split_transforms.7.bias\", \"conv2.2.split_transforms.7.running_mean\", \"conv2.2.split_transforms.7.running_var\", \"conv3.0.split_transforms.0.weight\", \"conv3.0.split_transforms.1.weight\", \"conv3.0.split_transforms.1.bias\", \"conv3.0.split_transforms.1.running_mean\", \"conv3.0.split_transforms.1.running_var\", \"conv3.0.split_transforms.3.weight\", \"conv3.0.split_transforms.4.weight\", \"conv3.0.split_transforms.4.bias\", \"conv3.0.split_transforms.4.running_mean\", \"conv3.0.split_transforms.4.running_var\", \"conv3.0.split_transforms.6.weight\", \"conv3.0.split_transforms.7.weight\", \"conv3.0.split_transforms.7.bias\", \"conv3.0.split_transforms.7.running_mean\", \"conv3.0.split_transforms.7.running_var\", \"conv3.0.shortcut.0.weight\", \"conv3.0.shortcut.1.weight\", \"conv3.0.shortcut.1.bias\", \"conv3.0.shortcut.1.running_mean\", \"conv3.0.shortcut.1.running_var\", \"conv3.1.split_transforms.0.weight\", \"conv3.1.split_transforms.1.weight\", \"conv3.1.split_transforms.1.bias\", \"conv3.1.split_transforms.1.running_mean\", \"conv3.1.split_transforms.1.running_var\", \"conv3.1.split_transforms.3.weight\", \"conv3.1.split_transforms.4.weight\", \"conv3.1.split_transforms.4.bias\", \"conv3.1.split_transforms.4.running_mean\", \"conv3.1.split_transforms.4.running_var\", \"conv3.1.split_transforms.6.weight\", \"conv3.1.split_transforms.7.weight\", \"conv3.1.split_transforms.7.bias\", \"conv3.1.split_transforms.7.running_mean\", \"conv3.1.split_transforms.7.running_var\", \"conv3.2.split_transforms.0.weight\", \"conv3.2.split_transforms.1.weight\", \"conv3.2.split_transforms.1.bias\", \"conv3.2.split_transforms.1.running_mean\", \"conv3.2.split_transforms.1.running_var\", \"conv3.2.split_transforms.3.weight\", \"conv3.2.split_transforms.4.weight\", \"conv3.2.split_transforms.4.bias\", \"conv3.2.split_transforms.4.running_mean\", \"conv3.2.split_transforms.4.running_var\", \"conv3.2.split_transforms.6.weight\", \"conv3.2.split_transforms.7.weight\", \"conv3.2.split_transforms.7.bias\", \"conv3.2.split_transforms.7.running_mean\", \"conv3.2.split_transforms.7.running_var\", \"conv3.3.split_transforms.0.weight\", \"conv3.3.split_transforms.1.weight\", \"conv3.3.split_transforms.1.bias\", \"conv3.3.split_transforms.1.running_mean\", \"conv3.3.split_transforms.1.running_var\", \"conv3.3.split_transforms.3.weight\", \"conv3.3.split_transforms.4.weight\", \"conv3.3.split_transforms.4.bias\", \"conv3.3.split_transforms.4.running_mean\", \"conv3.3.split_transforms.4.running_var\", \"conv3.3.split_transforms.6.weight\", \"conv3.3.split_transforms.7.weight\", \"conv3.3.split_transforms.7.bias\", \"conv3.3.split_transforms.7.running_mean\", \"conv3.3.split_transforms.7.running_var\", \"conv4.0.split_transforms.0.weight\", \"conv4.0.split_transforms.1.weight\", \"conv4.0.split_transforms.1.bias\", \"conv4.0.split_transforms.1.running_mean\", \"conv4.0.split_transforms.1.running_var\", \"conv4.0.split_transforms.3.weight\", \"conv4.0.split_transforms.4.weight\", \"conv4.0.split_transforms.4.bias\", \"conv4.0.split_transforms.4.running_mean\", \"conv4.0.split_transforms.4.running_var\", \"conv4.0.split_transforms.6.weight\", \"conv4.0.split_transforms.7.weight\", \"conv4.0.split_transforms.7.bias\", \"conv4.0.split_transforms.7.running_mean\", \"conv4.0.split_transforms.7.running_var\", \"conv4.0.shortcut.0.weight\", \"conv4.0.shortcut.1.weight\", \"conv4.0.shortcut.1.bias\", \"conv4.0.shortcut.1.running_mean\", \"conv4.0.shortcut.1.running_var\", \"conv4.1.split_transforms.0.weight\", \"conv4.1.split_transforms.1.weight\", \"conv4.1.split_transforms.1.bias\", \"conv4.1.split_transforms.1.running_mean\", \"conv4.1.split_transforms.1.running_var\", \"conv4.1.split_transforms.3.weight\", \"conv4.1.split_transforms.4.weight\", \"conv4.1.split_transforms.4.bias\", \"conv4.1.split_transforms.4.running_mean\", \"conv4.1.split_transforms.4.running_var\", \"conv4.1.split_transforms.6.weight\", \"conv4.1.split_transforms.7.weight\", \"conv4.1.split_transforms.7.bias\", \"conv4.1.split_transforms.7.running_mean\", \"conv4.1.split_transforms.7.running_var\", \"conv4.2.split_transforms.0.weight\", \"conv4.2.split_transforms.1.weight\", \"conv4.2.split_transforms.1.bias\", \"conv4.2.split_transforms.1.running_mean\", \"conv4.2.split_transforms.1.running_var\", \"conv4.2.split_transforms.3.weight\", \"conv4.2.split_transforms.4.weight\", \"conv4.2.split_transforms.4.bias\", \"conv4.2.split_transforms.4.running_mean\", \"conv4.2.split_transforms.4.running_var\", \"conv4.2.split_transforms.6.weight\", \"conv4.2.split_transforms.7.weight\", \"conv4.2.split_transforms.7.bias\", \"conv4.2.split_transforms.7.running_mean\", \"conv4.2.split_transforms.7.running_var\", \"conv4.3.split_transforms.0.weight\", \"conv4.3.split_transforms.1.weight\", \"conv4.3.split_transforms.1.bias\", \"conv4.3.split_transforms.1.running_mean\", \"conv4.3.split_transforms.1.running_var\", \"conv4.3.split_transforms.3.weight\", \"conv4.3.split_transforms.4.weight\", \"conv4.3.split_transforms.4.bias\", \"conv4.3.split_transforms.4.running_mean\", \"conv4.3.split_transforms.4.running_var\", \"conv4.3.split_transforms.6.weight\", \"conv4.3.split_transforms.7.weight\", \"conv4.3.split_transforms.7.bias\", \"conv4.3.split_transforms.7.running_mean\", \"conv4.3.split_transforms.7.running_var\", \"conv4.4.split_transforms.0.weight\", \"conv4.4.split_transforms.1.weight\", \"conv4.4.split_transforms.1.bias\", \"conv4.4.split_transforms.1.running_mean\", \"conv4.4.split_transforms.1.running_var\", \"conv4.4.split_transforms.3.weight\", \"conv4.4.split_transforms.4.weight\", \"conv4.4.split_transforms.4.bias\", \"conv4.4.split_transforms.4.running_mean\", \"conv4.4.split_transforms.4.running_var\", \"conv4.4.split_transforms.6.weight\", \"conv4.4.split_transforms.7.weight\", \"conv4.4.split_transforms.7.bias\", \"conv4.4.split_transforms.7.running_mean\", \"conv4.4.split_transforms.7.running_var\", \"conv4.5.split_transforms.0.weight\", \"conv4.5.split_transforms.1.weight\", \"conv4.5.split_transforms.1.bias\", \"conv4.5.split_transforms.1.running_mean\", \"conv4.5.split_transforms.1.running_var\", \"conv4.5.split_transforms.3.weight\", \"conv4.5.split_transforms.4.weight\", \"conv4.5.split_transforms.4.bias\", \"conv4.5.split_transforms.4.running_mean\", \"conv4.5.split_transforms.4.running_var\", \"conv4.5.split_transforms.6.weight\", \"conv4.5.split_transforms.7.weight\", \"conv4.5.split_transforms.7.bias\", \"conv4.5.split_transforms.7.running_mean\", \"conv4.5.split_transforms.7.running_var\", \"conv5.0.split_transforms.0.weight\", \"conv5.0.split_transforms.1.weight\", \"conv5.0.split_transforms.1.bias\", \"conv5.0.split_transforms.1.running_mean\", \"conv5.0.split_transforms.1.running_var\", \"conv5.0.split_transforms.3.weight\", \"conv5.0.split_transforms.4.weight\", \"conv5.0.split_transforms.4.bias\", \"conv5.0.split_transforms.4.running_mean\", \"conv5.0.split_transforms.4.running_var\", \"conv5.0.split_transforms.6.weight\", \"conv5.0.split_transforms.7.weight\", \"conv5.0.split_transforms.7.bias\", \"conv5.0.split_transforms.7.running_mean\", \"conv5.0.split_transforms.7.running_var\", \"conv5.0.shortcut.0.weight\", \"conv5.0.shortcut.1.weight\", \"conv5.0.shortcut.1.bias\", \"conv5.0.shortcut.1.running_mean\", \"conv5.0.shortcut.1.running_var\", \"conv5.1.split_transforms.0.weight\", \"conv5.1.split_transforms.1.weight\", \"conv5.1.split_transforms.1.bias\", \"conv5.1.split_transforms.1.running_mean\", \"conv5.1.split_transforms.1.running_var\", \"conv5.1.split_transforms.3.weight\", \"conv5.1.split_transforms.4.weight\", \"conv5.1.split_transforms.4.bias\", \"conv5.1.split_transforms.4.running_mean\", \"conv5.1.split_transforms.4.running_var\", \"conv5.1.split_transforms.6.weight\", \"conv5.1.split_transforms.7.weight\", \"conv5.1.split_transforms.7.bias\", \"conv5.1.split_transforms.7.running_mean\", \"conv5.1.split_transforms.7.running_var\", \"conv5.2.split_transforms.0.weight\", \"conv5.2.split_transforms.1.weight\", \"conv5.2.split_transforms.1.bias\", \"conv5.2.split_transforms.1.running_mean\", \"conv5.2.split_transforms.1.running_var\", \"conv5.2.split_transforms.3.weight\", \"conv5.2.split_transforms.4.weight\", \"conv5.2.split_transforms.4.bias\", \"conv5.2.split_transforms.4.running_mean\", \"conv5.2.split_transforms.4.running_var\", \"conv5.2.split_transforms.6.weight\", \"conv5.2.split_transforms.7.weight\", \"conv5.2.split_transforms.7.bias\", \"conv5.2.split_transforms.7.running_mean\", \"conv5.2.split_transforms.7.running_var\", \"fc1.weight\", \"fc1.bias\", \"fc2.weight\", \"fc2.bias\". \n\tUnexpected key(s) in state_dict: \"features.0.weight\", \"features.0.bias\", \"features.3.weight\", \"features.3.bias\", \"features.6.weight\", \"features.6.bias\", \"features.8.weight\", \"features.8.bias\", \"features.10.weight\", \"features.10.bias\", \"classifier.weight\", \"classifier.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20344/2798682198.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutilse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mutilse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'E:/KD_MI/experiments/base_cnn/cifar10/resnext/epoch14'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\KD_MI\\utilse.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[1;34m(checkpoint, model, optimizer)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'state_dict'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1481\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1482\u001b[1;33m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[0;32m   1483\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0;32m   1484\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNext:\n\tMissing key(s) in state_dict: \"conv1.0.weight\", \"conv1.1.weight\", \"conv1.1.bias\", \"conv1.1.running_mean\", \"conv1.1.running_var\", \"conv2.0.split_transforms.0.weight\", \"conv2.0.split_transforms.1.weight\", \"conv2.0.split_transforms.1.bias\", \"conv2.0.split_transforms.1.running_mean\", \"conv2.0.split_transforms.1.running_var\", \"conv2.0.split_transforms.3.weight\", \"conv2.0.split_transforms.4.weight\", \"conv2.0.split_transforms.4.bias\", \"conv2.0.split_transforms.4.running_mean\", \"conv2.0.split_transforms.4.running_var\", \"conv2.0.split_transforms.6.weight\", \"conv2.0.split_transforms.7.weight\", \"conv2.0.split_transforms.7.bias\", \"conv2.0.split_transforms.7.running_mean\", \"conv2.0.split_transforms.7.running_var\", \"conv2.0.shortcut.0.weight\", \"conv2.0.shortcut.1.weight\", \"conv2.0.shortcut.1.bias\", \"conv2.0.shortcut.1.running_mean\", \"conv2.0.shortcut.1.running_var\", \"conv2.1.split_transforms.0.weight\", \"conv2.1.split_transforms.1.weight\", \"conv2.1.split_transforms.1.bias\", \"conv2.1.split_transforms.1.running_mean\", \"conv2.1.split_transforms.1.running_var\", \"conv2.1.split_transforms.3.weight\", \"conv2.1.split_transforms.4.weight\", \"conv2.1.split_transforms.4.bias\", \"conv2.1.split_transforms.4.running_mean\", \"conv2.1.split_transforms.4.running_var\", \"conv2.1.split_transforms.6.weight\", \"conv2.1.split_transforms.7.weight\", \"conv2.1.split_transforms.7.bias\", \"conv2.1.split_transforms.7.running_mean\", \"conv2.1.split_transforms.7.running_var\", \"conv2.2.split_transforms.0.weight\", \"conv2.2.split_transforms.1.weight\", \"conv2.2.split_transforms.1.bias\", \"conv2.2.split_transforms.1.running_mean\", \"conv2.2.split_transforms.1.running_var\", \"conv2.2.split_transforms.3.weight\", \"conv2.2.split_transforms.4.weight\", \"conv2.2.split_transforms.4.bias\", \"conv2.2.split_transforms.4.running_mean\", \"conv2.2.split_transforms.4.running_var\", \"conv2.2.split_transforms.6.weight\", \"conv2.2.split_transforms.7.weight\", \"conv2.2.split_transforms.7.bias\", \"conv2.2.split_transforms.7.running_mean\", \"conv2.2.split_transforms.7.running_var\", \"conv3.0.split_transforms.0.weight\", \"conv3.0.split_transforms.1.weight\", \"conv3.0.split_transforms.1.bias\", \"conv3.0.split_transforms.1.running_mean\", \"conv3.0.split_transforms.1.running_var\", \"conv3.0.split_transforms.3.weight\", \"conv3.0.split_transforms.4.weight\", \"conv3.0.split_transforms.4.bias\", \"conv3.0.split_transforms.4.running_mean\", \"conv3.0.split_transforms.4.running_var\", \"conv3.0.split_transforms.6.weight\", \"conv3.0.split_transforms.7.weight\", \"conv3.0.split_transforms.7.bias\", \"conv3.0.split_transforms.7.running_mean\", \"conv3.0.split_transforms.7.running_var\", \"conv3.0.shortcut.0.weight\", \"conv3.0.shortcut.1.weight\", \"conv3.0.shortcut.1.bias\", \"conv3.0.shortcut.1.running_mean\", \"conv3.0.shortcut.1.running_var\", \"conv3.1.split_transforms.0.weight\", \"conv3.1.split_transforms.1.weight\", \"conv3.1.split_transforms.1.bias\", \"conv3.1.split_transforms.1.running_mean\", \"conv3.1.split_transforms.1.running_var\", \"conv3.1.split_transforms.3.weight\", \"conv3.1.split_transforms.4.weight\", \"conv3.1.split_transforms.4.bias\", \"conv3.1.split_transforms.4.running_mean\", \"conv3.1.split_transforms.4.running_var\", \"conv3.1.split_transforms.6.weight\", \"conv3.1.split_transforms.7.weight\", \"conv3.1.split_transforms.7.bias\", \"conv3.1.split_transforms.7.running_mean\", \"conv3.1.split_transforms.7.running_var\", \"conv3.2.split_transforms.0.weight\", \"conv3.2.split_transforms.1.weight\", \"conv3.2.split_transforms.1.bias\", \"conv3.2.split_transforms.1.running_mean\", \"conv3.2.split_transforms.1.running_var\", \"conv3.2.split_transforms.3.weight\", \"conv3.2.split_transforms.4.weight\", \"conv3.2.split_transforms.4.bias\", \"conv3.2.split_transforms.4.running_mean\", \"conv3.2.split_transforms.4.running_var\", \"conv3.2.split_transforms.6.weight\", \"conv3.2.split_transforms.7.weight\", \"conv3.2.split_transforms.7.bias\", \"conv3.2.split_transforms.7.running_mean\", \"conv3.2.split_transforms.7.running_var\", \"conv3.3.split_transforms.0.weight\", \"conv3.3.split_transforms.1.weight\", \"conv3.3.split_transforms.1.bias\", \"conv3.3.split_transforms.1.running_mean\", \"conv3.3.split_transforms.1.running_var\", \"conv3.3.split_transforms.3.weight\", \"conv3.3.split_transforms.4.weight\", \"conv3.3.split_transforms.4.bias\", \"conv3.3.split_transforms.4.running_mean\", \"conv3.3.split_transforms.4.running_var\", \"conv3.3.split_transforms.6.weight\", \"conv3.3.split_transforms.7.weight\", \"conv3.3.split_transforms.7.bias\", \"conv3.3.split_transforms.7.running_mean\", \"conv3.3.split_transforms.7.running_var\", \"conv4.0.split_transforms.0.weight\", \"conv4.0.split_transforms.1.weight\", \"conv4.0.split_transforms.1.bias\", \"conv4.0.split_transforms.1.running_mean\", \"conv4.0.split_transforms.1.running_var\", \"conv4.0.split_transforms.3.weight\", \"conv4.0.split_transforms.4.weight\", \"conv4.0.split_transforms.4.bias\", \"conv4.0.split_transforms.4.running_mean\", \"conv4.0.split_transforms.4.running_var\", \"conv4.0.split_transforms.6.weight\", \"conv4.0.split_transforms.7.weight\", \"conv4.0.split_transforms.7.bias\", \"conv4.0.split_transforms.7.running_mean\", \"conv4.0.split_transforms.7.running_var\", \"conv4.0.shortcut.0.weight\", \"conv4.0.shortcut.1.weight\", \"conv4.0.shortcut.1.bias\", \"conv4.0.shortcut.1.running_mean\", \"conv4.0.shortcut.1.running_var\", \"conv4.1.split_transforms.0.weight\", \"conv4.1.split_transforms.1.weight\", \"conv4.1.split_transforms.1.bias\", \"conv4.1.split_transforms.1.running_mean\", \"conv4.1.split_transforms.1.running_var\", \"conv4.1.split_transforms.3.weight\", \"conv4.1.split_transforms.4.weight\", \"conv4.1.split_transforms.4.bias\", \"conv4.1.split_transforms.4.running_mean\", \"conv4.1.split_transforms.4.running_var\", \"conv4.1.split_transforms.6.weight\", \"conv4.1.split_transforms.7.weight\", \"conv4.1.split_transforms.7.bias\", \"conv4.1.split_transforms.7.running_mean\", \"conv4.1.split_transforms.7.running_var\", \"conv4.2.split_transforms.0.weight\", \"conv4.2.split_transforms.1.weight\", \"conv4.2.split_transforms.1.bias\", \"conv4.2.split_transforms.1.running_mean\", \"conv4.2.split_transforms.1.running_var\", \"conv4.2.split_transforms.3.weight\", \"conv4.2.split_transforms.4.weight\", \"conv4.2.split_transforms.4.bias\", \"conv4.2.split_transforms.4.running_mean\", \"conv4.2.split_transforms.4.running_var\", \"conv4.2.split_transforms.6.weight\", \"conv4.2.split_transforms.7.weight\", \"conv4.2.split_transforms.7.bias\", \"conv4.2.split_transforms.7.running_mean\", \"conv4.2.split_transforms.7.running_var\", \"conv4.3.split_transforms.0.weight\", \"conv4.3.split_transforms.1.weight\", \"conv4.3.split_transforms.1.bias\", \"conv4.3.split_transforms.1.running_mean\", \"conv4.3.split_transforms.1.running_var\", \"conv4.3.split_transforms.3.weight\", \"conv4.3.split_transforms.4.weight\", \"conv4.3.split_transforms.4.bias\", \"conv4.3.split_transforms.4.running_mean\", \"conv4.3.split_transforms.4.running_var\", \"conv4.3.split_transforms.6.weight\", \"conv4.3.split_transforms.7.weight\", \"conv4.3.split_transforms.7.bias\", \"conv4.3.split_transforms.7.running_mean\", \"conv4.3.split_transforms.7.running_var\", \"conv4.4.split_transforms.0.weight\", \"conv4.4.split_transforms.1.weight\", \"conv4.4.split_transforms.1.bias\", \"conv4.4.split_transforms.1.running_mean\", \"conv4.4.split_transforms.1.running_var\", \"conv4.4.split_transforms.3.weight\", \"conv4.4.split_transforms.4.weight\", \"conv4.4.split_transforms.4.bias\", \"conv4.4.split_transforms.4.running_mean\", \"conv4.4.split_transforms.4.running_var\", \"conv4.4.split_transforms.6.weight\", \"conv4.4.split_transforms.7.weight\", \"conv4.4.split_transforms.7.bias\", \"conv4.4.split_transforms.7.running_mean\", \"conv4.4.split_transforms.7.running_var\", \"conv4.5.split_transforms.0.weight\", \"conv4.5.split_transforms.1.weight\", \"conv4.5.split_transforms.1.bias\", \"conv4.5.split_transforms.1.running_mean\", \"conv4.5.split_transforms.1.running_var\", \"conv4.5.split_transforms.3.weight\", \"conv4.5.split_transforms.4.weight\", \"conv4.5.split_transforms.4.bias\", \"conv4.5.split_transforms.4.running_mean\", \"conv4.5.split_transforms.4.running_var\", \"conv4.5.split_transforms.6.weight\", \"conv4.5.split_transforms.7.weight\", \"conv4.5.split_transforms.7.bias\", \"conv4.5.split_transforms.7.running_mean\", \"conv4.5.split_transforms.7.running_var\", \"conv5.0.split_transforms.0.weight\", \"conv5.0.split_transforms.1.weight\", \"conv5.0.split_transforms.1.bias\", \"conv5.0.split_transforms.1.running_mean\", \"conv5.0.split_transforms.1.running_var\", \"conv5.0.split_transforms.3.weight\", \"conv5.0.split_transforms.4.weight\", \"conv5.0.split_transforms.4.bias\", \"conv5.0.split_transforms.4.running_mean\", \"conv5.0.split_transforms.4.running_var\", \"conv5.0.split_transforms.6.weight\", \"conv5.0.split_transforms.7.weight\", \"conv5.0.split_transforms.7.bias\", \"conv5.0.split_transforms.7.running_mean\", \"conv5.0.split_transforms.7.running_var\", \"conv5.0.shortcut.0.weight\", \"conv5.0.shortcut.1.weight\", \"conv5.0.shortcut.1.bias\", \"conv5.0.shortcut.1.running_mean\", \"conv5.0.shortcut.1.running_var\", \"conv5.1.split_transforms.0.weight\", \"conv5.1.split_transforms.1.weight\", \"conv5.1.split_transforms.1.bias\", \"conv5.1.split_transforms.1.running_mean\", \"conv5.1.split_transforms.1.running_var\", \"conv5.1.split_transforms.3.weight\", \"conv5.1.split_transforms.4.weight\", \"conv5.1.split_transforms.4.bias\", \"conv5.1.split_transforms.4.running_mean\", \"conv5.1.split_transforms.4.running_var\", \"conv5.1.split_transforms.6.weight\", \"conv5.1.split_transforms.7.weight\", \"conv5.1.split_transforms.7.bias\", \"conv5.1.split_transforms.7.running_mean\", \"conv5.1.split_transforms.7.running_var\", \"conv5.2.split_transforms.0.weight\", \"conv5.2.split_transforms.1.weight\", \"conv5.2.split_transforms.1.bias\", \"conv5.2.split_transforms.1.running_mean\", \"conv5.2.split_transforms.1.running_var\", \"conv5.2.split_transforms.3.weight\", \"conv5.2.split_transforms.4.weight\", \"conv5.2.split_transforms.4.bias\", \"conv5.2.split_transforms.4.running_mean\", \"conv5.2.split_transforms.4.running_var\", \"conv5.2.split_transforms.6.weight\", \"conv5.2.split_transforms.7.weight\", \"conv5.2.split_transforms.7.bias\", \"conv5.2.split_transforms.7.running_mean\", \"conv5.2.split_transforms.7.running_var\", \"fc1.weight\", \"fc1.bias\", \"fc2.weight\", \"fc2.bias\". \n\tUnexpected key(s) in state_dict: \"features.0.weight\", \"features.0.bias\", \"features.3.weight\", \"features.3.bias\", \"features.6.weight\", \"features.6.bias\", \"features.8.weight\", \"features.8.bias\", \"features.10.weight\", \"features.10.bias\", \"classifier.weight\", \"classifier.bias\". "
     ]
    }
   ],
   "source": [
    "# use GPU if available\n",
    "import utilse\n",
    "\n",
    "utilse.load_checkpoint('E:/KD_MI/experiments/base_cnn/cifar10/resnext/epoch14',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1336f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
